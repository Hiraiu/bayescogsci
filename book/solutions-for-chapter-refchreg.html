<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>12.2 Solutions for chapter 4  | An Introduction to Bayesian Data Analysis for Cognitive Science</title>
  <meta name="description" content="An introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="12.2 Solutions for chapter 4  | An Introduction to Bayesian Data Analysis for Cognitive Science" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://vasishth.github.io/Bayes_CogSci/" />
  <meta property="og:image" content="https://vasishth.github.io/Bayes_CogSci/images/temporarycover.jpg" />
  <meta property="og:description" content="An introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="github-repo" content="https://github.com/vasishth/Bayes_CogSci" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="12.2 Solutions for chapter 4  | An Introduction to Bayesian Data Analysis for Cognitive Science" />
  
  <meta name="twitter:description" content="An introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="twitter:image" content="https://vasishth.github.io/Bayes_CogSci/images/temporarycover.jpg" />

<meta name="author" content="Bruno Nicenboim, Daniel Schad, and Shravan Vasishth" />


<meta name="date" content="2020-06-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="solutions-for-chapter-refchcompbda.html"/>
<link rel="next" href="solutions-for-chapter-refchhierarchical.html"/>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<script type="text/javascript">

 /* Uncomment this and comment the next one to show the solutions */

 /* $(document).ready(function() {
  *     $folds = $(".solution");
  *     $folds.wrapInner("<div class=\"solution-blck\">"); // wrap a div container around content
  *     $folds.prepend("<button class=\"solution-btn\">Show solution</button>");  // add a button
  *     $(".solution-blck").toggle();  // fold all blocks
  *     $(".solution-btn").on("click", function() {  // add onClick event
  *         $(this).text($(this).text() === "Hide solution" ? "Show solution" : "Hide solution");  // if the text equals "Hide solution", change it to "Show solution"or else to "Hide solution" 
  *         $(this).next(".solution-blck").toggle("linear");  // "swing" is the default easing function. This can be further customized in its speed or the overall animation itself.
  *     })
  * }); */

 $(document).ready(function() {
     $folds = $(".solution");
     $folds.wrapInner("<div class=\"solution-blck\">"); // wrap a div container around content
     $folds.prepend("<button class=\"solution-btn\"></button>");  // add a button
     $(".solution-blck").toggle();  // fold all blocks
     $(".solution-btn").on("click", function() {  // add onClick event
         /* $(this).text($(this).text() === "Hide solution" ? "Show solution" : "Hide solution");  // if the text equals "Hide solution", change it to "Show solution"or else to "Hide solution"  */
         /* $(this).next(".solution-blck").toggle("linear");  // "swing" is the default easing function. This can be further customized in its speed or the overall animation itself. */
     })
 });

</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Data Analysis for Cognitive Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i><b>0.1</b> Prerequisites</a></li>
<li class="chapter" data-level="0.2" data-path="developing-the-right-mindset-for-this-book.html"><a href="developing-the-right-mindset-for-this-book.html"><i class="fa fa-check"></i><b>0.2</b> Developing the right mindset for this book</a></li>
<li class="chapter" data-level="0.3" data-path="how-to-read-this-book.html"><a href="how-to-read-this-book.html"><i class="fa fa-check"></i><b>0.3</b> How to read this book</a></li>
<li class="chapter" data-level="0.4" data-path="online-materials.html"><a href="online-materials.html"><i class="fa fa-check"></i><b>0.4</b> Online materials</a></li>
<li class="chapter" data-level="0.5" data-path="software-needed.html"><a href="software-needed.html"><i class="fa fa-check"></i><b>0.5</b> Software needed</a></li>
<li class="chapter" data-level="0.6" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i><b>0.6</b> Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introprob.html"><a href="introprob.html"><i class="fa fa-check"></i><b>1.1</b> Probability</a></li>
<li class="chapter" data-level="1.2" data-path="conditional-probability.html"><a href="conditional-probability.html"><i class="fa fa-check"></i><b>1.2</b> Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path="sec-binomialcloze.html"><a href="sec-binomialcloze.html"><i class="fa fa-check"></i><b>1.3</b> Discrete random variables: An example using the Binomial distribution</a><ul>
<li class="chapter" data-level="1.3.1" data-path="sec-binomialcloze.html"><a href="sec-binomialcloze.html#the-mean-and-variance-of-the-binomial-distribution"><i class="fa fa-check"></i><b>1.3.1</b> The mean and variance of the Binomial distribution</a></li>
<li class="chapter" data-level="1.3.2" data-path="sec-binomialcloze.html"><a href="sec-binomialcloze.html#what-information-does-a-probability-distribution-provide"><i class="fa fa-check"></i><b>1.3.2</b> What information does a probability distribution provide?</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="continuous-random-variables-an-example-using-the-normal-distribution.html"><a href="continuous-random-variables-an-example-using-the-normal-distribution.html"><i class="fa fa-check"></i><b>1.4</b> Continuous random variables: An example using the Normal distribution</a><ul>
<li class="chapter" data-level="1.4.1" data-path="continuous-random-variables-an-example-using-the-normal-distribution.html"><a href="continuous-random-variables-an-example-using-the-normal-distribution.html#an-important-distinction-probability-vs.density-in-a-continuous-random-variable"><i class="fa fa-check"></i><b>1.4.1</b> An important distinction: probability vs. density in a continuous random variable</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="an-important-concept-the-marginal-likelihood-integrating-out-a-parameter.html"><a href="an-important-concept-the-marginal-likelihood-integrating-out-a-parameter.html"><i class="fa fa-check"></i><b>1.5</b> An important concept: The marginal likelihood (integrating out a parameter)</a></li>
<li class="chapter" data-level="1.6" data-path="summary-of-useful-r-functions-relating-to-distributions.html"><a href="summary-of-useful-r-functions-relating-to-distributions.html"><i class="fa fa-check"></i><b>1.6</b> Summary of useful R functions relating to distributions</a></li>
<li class="chapter" data-level="1.7" data-path="summary-of-concepts-introduced-in-this-chapter.html"><a href="summary-of-concepts-introduced-in-this-chapter.html"><i class="fa fa-check"></i><b>1.7</b> Summary of concepts introduced in this chapter</a></li>
<li class="chapter" data-level="1.8" data-path="further-reading.html"><a href="further-reading.html"><i class="fa fa-check"></i><b>1.8</b> Further reading</a></li>
<li class="chapter" data-level="1.9" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.9</b> Exercises</a><ul>
<li class="chapter" data-level="1.9.1" data-path="exercises.html"><a href="exercises.html#practice-using-the-pnorm-function"><i class="fa fa-check"></i><b>1.9.1</b> Practice using the <code>pnorm</code> function</a></li>
<li class="chapter" data-level="1.9.2" data-path="exercises.html"><a href="exercises.html#practice-using-the-qnorm-function"><i class="fa fa-check"></i><b>1.9.2</b> Practice using the <code>qnorm</code> function</a></li>
<li class="chapter" data-level="1.9.3" data-path="exercises.html"><a href="exercises.html#practice-using-qt"><i class="fa fa-check"></i><b>1.9.3</b> Practice using <code>qt</code></a></li>
<li class="chapter" data-level="1.9.4" data-path="exercises.html"><a href="exercises.html#maximum-likelihood-estimation-1"><i class="fa fa-check"></i><b>1.9.4</b> Maximum likelihood estimation 1</a></li>
<li class="chapter" data-level="1.9.5" data-path="exercises.html"><a href="exercises.html#maximum-likelihood-estimation-2"><i class="fa fa-check"></i><b>1.9.5</b> Maximum likelihood estimation 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introBDA.html"><a href="introBDA.html"><i class="fa fa-check"></i><b>2</b> Introduction to Bayesian data analysis</a><ul>
<li class="chapter" data-level="2.1" data-path="sec-analytical.html"><a href="sec-analytical.html"><i class="fa fa-check"></i><b>2.1</b> Deriving the posterior using Bayes’ rule: An analytical example</a><ul>
<li class="chapter" data-level="2.1.1" data-path="sec-analytical.html"><a href="sec-analytical.html#choosing-a-likelihood"><i class="fa fa-check"></i><b>2.1.1</b> Choosing a likelihood</a></li>
<li class="chapter" data-level="2.1.2" data-path="sec-analytical.html"><a href="sec-analytical.html#choosing-a-prior-for-theta"><i class="fa fa-check"></i><b>2.1.2</b> Choosing a prior for <span class="math inline">\(\theta\)</span></a></li>
<li class="chapter" data-level="2.1.3" data-path="sec-analytical.html"><a href="sec-analytical.html#using-bayes-rule-to-compute-the-posterior-pthetank"><i class="fa fa-check"></i><b>2.1.3</b> Using Bayes’ rule to compute the posterior <span class="math inline">\(p(\theta|n,k)\)</span></a></li>
<li class="chapter" data-level="2.1.4" data-path="sec-analytical.html"><a href="sec-analytical.html#summary-of-the-procedure"><i class="fa fa-check"></i><b>2.1.4</b> Summary of the procedure</a></li>
<li class="chapter" data-level="2.1.5" data-path="sec-analytical.html"><a href="sec-analytical.html#visualizing-the-prior-likelihood-and-the-posterior"><i class="fa fa-check"></i><b>2.1.5</b> Visualizing the prior, likelihood, and the posterior</a></li>
<li class="chapter" data-level="2.1.6" data-path="sec-analytical.html"><a href="sec-analytical.html#the-posterior-distribution-is-a-compromise-between-the-prior-and-the-likelihood"><i class="fa fa-check"></i><b>2.1.6</b> The posterior distribution is a compromise between the prior and the likelihood</a></li>
<li class="chapter" data-level="2.1.7" data-path="sec-analytical.html"><a href="sec-analytical.html#incremental-knowledge-gain-using-prior-knowledge"><i class="fa fa-check"></i><b>2.1.7</b> Incremental knowledge gain using prior knowledge</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="summary-of-concepts-introduced-in-this-chapter-1.html"><a href="summary-of-concepts-introduced-in-this-chapter-1.html"><i class="fa fa-check"></i><b>2.2</b> Summary of concepts introduced in this chapter</a></li>
<li class="chapter" data-level="2.3" data-path="further-reading-1.html"><a href="further-reading-1.html"><i class="fa fa-check"></i><b>2.3</b> Further reading</a></li>
<li class="chapter" data-level="2.4" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>2.4</b> Exercises</a><ul>
<li class="chapter" data-level="2.4.1" data-path="exercises-1.html"><a href="exercises-1.html#exercise-deriving-bayes-rule"><i class="fa fa-check"></i><b>2.4.1</b> Exercise: Deriving Bayes’ rule</a></li>
<li class="chapter" data-level="2.4.2" data-path="exercises-1.html"><a href="exercises-1.html#exercise-conjugate-forms-1"><i class="fa fa-check"></i><b>2.4.2</b> Exercise: Conjugate forms 1</a></li>
<li class="chapter" data-level="2.4.3" data-path="exercises-1.html"><a href="exercises-1.html#exercise-conjugate-forms-2"><i class="fa fa-check"></i><b>2.4.3</b> Exercise: Conjugate forms 2</a></li>
<li class="chapter" data-level="2.4.4" data-path="exercises-1.html"><a href="exercises-1.html#exercise-conjugate-forms-3"><i class="fa fa-check"></i><b>2.4.4</b> Exercise: Conjugate forms 3</a></li>
<li class="chapter" data-level="2.4.5" data-path="exercises-1.html"><a href="exercises-1.html#exercise-conjugate-forms-4"><i class="fa fa-check"></i><b>2.4.5</b> Exercise: Conjugate forms 4</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch-compbda.html"><a href="ch-compbda.html"><i class="fa fa-check"></i><b>3</b> Computational Bayesian data analysis</a><ul>
<li class="chapter" data-level="3.1" data-path="deriving-the-posterior-through-sampling.html"><a href="deriving-the-posterior-through-sampling.html"><i class="fa fa-check"></i><b>3.1</b> Deriving the posterior through sampling</a><ul>
<li class="chapter" data-level="3.1.1" data-path="deriving-the-posterior-through-sampling.html"><a href="deriving-the-posterior-through-sampling.html#bayesian-regression-models-using-stan-brms"><i class="fa fa-check"></i><b>3.1.1</b> Bayesian Regression Models using ‘Stan’: brms</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sec-priorpred.html"><a href="sec-priorpred.html"><i class="fa fa-check"></i><b>3.2</b> Prior predictive distribution</a></li>
<li class="chapter" data-level="3.3" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html"><i class="fa fa-check"></i><b>3.3</b> The influence of priors: sensitivity analysis</a><ul>
<li class="chapter" data-level="3.3.1" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html#flat-uninformative-priors"><i class="fa fa-check"></i><b>3.3.1</b> Flat uninformative priors</a></li>
<li class="chapter" data-level="3.3.2" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html#regularizing-priors"><i class="fa fa-check"></i><b>3.3.2</b> Regularizing priors</a></li>
<li class="chapter" data-level="3.3.3" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html#principled-priors"><i class="fa fa-check"></i><b>3.3.3</b> Principled priors</a></li>
<li class="chapter" data-level="3.3.4" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html#informative-priors"><i class="fa fa-check"></i><b>3.3.4</b> Informative priors</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="sec-revisit.html"><a href="sec-revisit.html"><i class="fa fa-check"></i><b>3.4</b> Revisiting the button-pressing example with different priors</a></li>
<li class="chapter" data-level="3.5" data-path="sec-ppd.html"><a href="sec-ppd.html"><i class="fa fa-check"></i><b>3.5</b> Posterior predictive distribution</a><ul>
<li class="chapter" data-level="3.5.1" data-path="sec-ppd.html"><a href="sec-ppd.html#comparing-different-likelihoods"><i class="fa fa-check"></i><b>3.5.1</b> Comparing different likelihoods</a></li>
<li class="chapter" data-level="3.5.2" data-path="sec-ppd.html"><a href="sec-ppd.html#sec:lnfirst"><i class="fa fa-check"></i><b>3.5.2</b> The log-normal likelihood</a></li>
<li class="chapter" data-level="3.5.3" data-path="sec-ppd.html"><a href="sec-ppd.html#sec:lognormal"><i class="fa fa-check"></i><b>3.5.3</b> Re-fitting a single participant pressing a button repeatedly with a log-normal likelihood</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>3.6</b> Summary</a></li>
<li class="chapter" data-level="3.7" data-path="further-reading-2.html"><a href="further-reading-2.html"><i class="fa fa-check"></i><b>3.7</b> Further reading</a></li>
<li class="chapter" data-level="3.8" data-path="ex-compbda.html"><a href="ex-compbda.html"><i class="fa fa-check"></i><b>3.8</b> Exercises</a><ul>
<li class="chapter" data-level="3.8.1" data-path="ex-compbda.html"><a href="ex-compbda.html#a-simple-linear-model-exercises-section-refsecsimplenormal"><i class="fa fa-check"></i><b>3.8.1</b> A simple linear model exercises (Section @ref(sec:simplenormal))</a></li>
<li class="chapter" data-level="3.8.2" data-path="ex-compbda.html"><a href="ex-compbda.html#revisiting-the-button-pressing-example-with-different-priors-exercises-section-refsecrevisit"><i class="fa fa-check"></i><b>3.8.2</b> Revisiting the button-pressing example with different priors exercises (Section @ref(sec:revisit))</a></li>
<li class="chapter" data-level="3.8.3" data-path="ex-compbda.html"><a href="ex-compbda.html#posterior-predictive-distribution-and-log-normal-model-exercises-section-refsecppd"><i class="fa fa-check"></i><b>3.8.3</b> Posterior predictive distribution and log-normal model exercises (Section @ref(sec:ppd))</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>3.9</b> Appendix</a><ul>
<li class="chapter" data-level="3.9.1" data-path="appendix.html"><a href="appendix.html#app:pp"><i class="fa fa-check"></i><b>3.9.1</b> Generating prior predictive distributions with <code>brms</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-reg.html"><a href="ch-reg.html"><i class="fa fa-check"></i><b>4</b> Bayesian regression models</a><ul>
<li class="chapter" data-level="4.1" data-path="sec-pupil.html"><a href="sec-pupil.html"><i class="fa fa-check"></i><b>4.1</b> A first linear regression: Does attentional load affect pupil size?</a><ul>
<li class="chapter" data-level="4.1.1" data-path="sec-pupil.html"><a href="sec-pupil.html#likelihood-and-priors"><i class="fa fa-check"></i><b>4.1.1</b> Likelihood and priors</a></li>
<li class="chapter" data-level="4.1.2" data-path="sec-pupil.html"><a href="sec-pupil.html#the-brms-model"><i class="fa fa-check"></i><b>4.1.2</b> The <code>brms</code> model</a></li>
<li class="chapter" data-level="4.1.3" data-path="sec-pupil.html"><a href="sec-pupil.html#how-to-communicate-the-results"><i class="fa fa-check"></i><b>4.1.3</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.1.4" data-path="sec-pupil.html"><a href="sec-pupil.html#sec:pupiladq"><i class="fa fa-check"></i><b>4.1.4</b> Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sec-trial.html"><a href="sec-trial.html"><i class="fa fa-check"></i><b>4.2</b> Log-normal model: Does trial affect reaction times?</a><ul>
<li class="chapter" data-level="4.2.1" data-path="sec-trial.html"><a href="sec-trial.html#likelihood-and-priors-for-the-log-normal-model"><i class="fa fa-check"></i><b>4.2.1</b> Likelihood and priors for the log-normal model</a></li>
<li class="chapter" data-level="4.2.2" data-path="sec-trial.html"><a href="sec-trial.html#the-brms-model-1"><i class="fa fa-check"></i><b>4.2.2</b> The <code>brms</code> model</a></li>
<li class="chapter" data-level="4.2.3" data-path="sec-trial.html"><a href="sec-trial.html#how-to-communicate-the-results-1"><i class="fa fa-check"></i><b>4.2.3</b> How to communicate the results?</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="sec-logistic.html"><a href="sec-logistic.html"><i class="fa fa-check"></i><b>4.3</b> Logistic regression: Does set size affect free recall?</a><ul>
<li class="chapter" data-level="4.3.1" data-path="sec-logistic.html"><a href="sec-logistic.html#the-likelihood-for-the-logistic-regression-model"><i class="fa fa-check"></i><b>4.3.1</b> The likelihood for the logistic regression model</a></li>
<li class="chapter" data-level="4.3.2" data-path="sec-logistic.html"><a href="sec-logistic.html#priors-for-the-logistic-regression"><i class="fa fa-check"></i><b>4.3.2</b> Priors for the logistic regression</a></li>
<li class="chapter" data-level="4.3.3" data-path="sec-logistic.html"><a href="sec-logistic.html#the-brms-model-2"><i class="fa fa-check"></i><b>4.3.3</b> The <code>brms</code> model</a></li>
<li class="chapter" data-level="4.3.4" data-path="sec-logistic.html"><a href="sec-logistic.html#how-to-communicate-the-results-2"><i class="fa fa-check"></i><b>4.3.4</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.3.5" data-path="sec-logistic.html"><a href="sec-logistic.html#descriptive-adequacy"><i class="fa fa-check"></i><b>4.3.5</b> Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>4.4</b> Summary</a></li>
<li class="chapter" data-level="4.5" data-path="further-reading-3.html"><a href="further-reading-3.html"><i class="fa fa-check"></i><b>4.5</b> Further reading</a></li>
<li class="chapter" data-level="4.6" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a><ul>
<li class="chapter" data-level="4.6.1" data-path="exercises-2.html"><a href="exercises-2.html#a-first-linear-regression-exercises-section-refsecpupil"><i class="fa fa-check"></i><b>4.6.1</b> A first linear regression exercises (Section @ref(sec:pupil))</a></li>
<li class="chapter" data-level="4.6.2" data-path="exercises-2.html"><a href="exercises-2.html#log-normal-model-exercises-section-refsectrial"><i class="fa fa-check"></i><b>4.6.2</b> Log-normal model exercises (Section @ref(sec:trial))</a></li>
<li class="chapter" data-level="4.6.3" data-path="exercises-2.html"><a href="exercises-2.html#logistic-regression-exercises-section-refseclogistic"><i class="fa fa-check"></i><b>4.6.3</b> Logistic regression exercises (section @ref(sec:logistic))</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="appendix-1.html"><a href="appendix-1.html"><i class="fa fa-check"></i><b>4.7</b> Appendix</a><ul>
<li class="chapter" data-level="4.7.1" data-path="appendix-1.html"><a href="appendix-1.html#sec:preprocessingpupil"><i class="fa fa-check"></i><b>4.7.1</b> Preparation of the pupil size data (section @ref(sec:pupil))</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html"><i class="fa fa-check"></i><b>5</b> Bayesian hierarchical models</a><ul>
<li class="chapter" data-level="5.1" data-path="a-hierarchical-normal-model-the-n400-effect.html"><a href="a-hierarchical-normal-model-the-n400-effect.html"><i class="fa fa-check"></i><b>5.1</b> A hierarchical normal model: The N400 effect</a><ul>
<li class="chapter" data-level="5.1.1" data-path="a-hierarchical-normal-model-the-n400-effect.html"><a href="a-hierarchical-normal-model-the-n400-effect.html#complete-pooling-model-m_cp"><i class="fa fa-check"></i><b>5.1.1</b> Complete-pooling model (<span class="math inline">\(M_{cp}\)</span>)</a></li>
<li class="chapter" data-level="5.1.2" data-path="a-hierarchical-normal-model-the-n400-effect.html"><a href="a-hierarchical-normal-model-the-n400-effect.html#no-pooling-model-m_np"><i class="fa fa-check"></i><b>5.1.2</b> No-pooling model (<span class="math inline">\(M_{np}\)</span>)</a></li>
<li class="chapter" data-level="5.1.3" data-path="a-hierarchical-normal-model-the-n400-effect.html"><a href="a-hierarchical-normal-model-the-n400-effect.html#sec:uncorrelated"><i class="fa fa-check"></i><b>5.1.3</b> Varying intercept and varying slopes model (<span class="math inline">\(M_{v}\)</span>)</a></li>
<li class="chapter" data-level="5.1.4" data-path="a-hierarchical-normal-model-the-n400-effect.html"><a href="a-hierarchical-normal-model-the-n400-effect.html#sec:mcvivs"><i class="fa fa-check"></i><b>5.1.4</b> Correlated varying intercept varying slopes model (<span class="math inline">\(M_{h}\)</span>)</a></li>
<li class="chapter" data-level="5.1.5" data-path="a-hierarchical-normal-model-the-n400-effect.html"><a href="a-hierarchical-normal-model-the-n400-effect.html#sec:sih"><i class="fa fa-check"></i><b>5.1.5</b> By-subjects and by-items correlated varying intercept varying slopes model (<span class="math inline">\(M_{sih}\)</span>)</a></li>
<li class="chapter" data-level="5.1.6" data-path="a-hierarchical-normal-model-the-n400-effect.html"><a href="a-hierarchical-normal-model-the-n400-effect.html#sec:distrmodel"><i class="fa fa-check"></i><b>5.1.6</b> Beyond the so-called maximal models–Distributional regression models</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="sec-stroop.html"><a href="sec-stroop.html"><i class="fa fa-check"></i><b>5.2</b> A hierarchical log-normal model: The Stroop effect</a><ul>
<li class="chapter" data-level="5.2.1" data-path="sec-stroop.html"><a href="sec-stroop.html#a-correlated-varying-intercept-varying-slopes-log-normal-model"><i class="fa fa-check"></i><b>5.2.1</b> A correlated varying intercept varying slopes log-normal model</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="summary-2.html"><a href="summary-2.html"><i class="fa fa-check"></i><b>5.3</b> Summary</a><ul>
<li class="chapter" data-level="5.3.1" data-path="summary-2.html"><a href="summary-2.html#why-should-we-take-the-trouble-of-fitting-a-bayesian-hierarchical-model"><i class="fa fa-check"></i><b>5.3.1</b> Why should we take the trouble of fitting a Bayesian hierarchical model?</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="further-reading-4.html"><a href="further-reading-4.html"><i class="fa fa-check"></i><b>5.4</b> Further reading</a></li>
<li class="chapter" data-level="5.5" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>5.5</b> Exercises</a><ul>
<li class="chapter" data-level="5.5.1" data-path="exercises-3.html"><a href="exercises-3.html#ex:hierarchical-logn"><i class="fa fa-check"></i><b>5.5.1</b> Hierarchical model with a lognormal likelihood.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch-contr.html"><a href="ch-contr.html"><i class="fa fa-check"></i><b>6</b> Contrast coding, interactions, etc</a></li>
<li class="chapter" data-level="7" data-path="ch-bf.html"><a href="ch-bf.html"><i class="fa fa-check"></i><b>7</b> Model comparison using Bayes factors</a><ul>
<li class="chapter" data-level="7.1" data-path="summary-3.html"><a href="summary-3.html"><i class="fa fa-check"></i><b>7.1</b> Summary</a></li>
<li class="chapter" data-level="7.2" data-path="further-reading-5.html"><a href="further-reading-5.html"><i class="fa fa-check"></i><b>7.2</b> Further reading</a></li>
<li class="chapter" data-level="7.3" data-path="exercises-4.html"><a href="exercises-4.html"><i class="fa fa-check"></i><b>7.3</b> Exercises</a><ul>
<li class="chapter" data-level="7.3.1" data-path="exercises-4.html"><a href="exercises-4.html#ex:bf-logn"><i class="fa fa-check"></i><b>7.3.1</b> Bayes factor for a hierarchical model with a lognormal likelihood.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ch-remame.html"><a href="ch-remame.html"><i class="fa fa-check"></i><b>8</b> Meta-analysis and measurement error models</a></li>
<li class="chapter" data-level="9" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>9</b> Introduction</a></li>
<li class="chapter" data-level="10" data-path="meta-analysis.html"><a href="meta-analysis.html"><i class="fa fa-check"></i><b>10</b> Meta-analysis</a><ul>
<li class="chapter" data-level="10.0.1" data-path="meta-analysis.html"><a href="meta-analysis.html#random-effects-meta-analysis-brms-implementation"><i class="fa fa-check"></i><b>10.0.1</b> Random-effects meta-analysis: brms implementation</a></li>
<li class="chapter" data-level="10.0.2" data-path="meta-analysis.html"><a href="meta-analysis.html#random-effects-meta-analysis-stan-implementation"><i class="fa fa-check"></i><b>10.0.2</b> Random-effects meta-analysis: Stan implementation</a></li>
<li class="chapter" data-level="10.1" data-path="summary-4.html"><a href="summary-4.html"><i class="fa fa-check"></i><b>10.1</b> Summary</a></li>
<li class="chapter" data-level="10.2" data-path="further-reading-6.html"><a href="further-reading-6.html"><i class="fa fa-check"></i><b>10.2</b> Further reading</a></li>
<li class="chapter" data-level="10.3" data-path="exercises-5.html"><a href="exercises-5.html"><i class="fa fa-check"></i><b>10.3</b> Exercises</a><ul>
<li class="chapter" data-level="10.3.1" data-path="exercises-4.html"><a href="exercises-4.html#ex:bf-logn"><i class="fa fa-check"></i><b>10.3.1</b> Bayes factor for a hierarchical model with a lognormal likelihood.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="important-distributions.html"><a href="important-distributions.html"><i class="fa fa-check"></i><b>11</b> Important distributions</a></li>
<li class="chapter" data-level="12" data-path="solutions.html"><a href="solutions.html"><i class="fa fa-check"></i><b>12</b> Solutions</a><ul>
<li class="chapter" data-level="12.1" data-path="solutions-for-chapter-refchcompbda.html"><a href="solutions-for-chapter-refchcompbda.html"><i class="fa fa-check"></i><b>12.1</b> Solutions for chapter @ref(ch:compbda) </a></li>
<li class="chapter" data-level="12.2" data-path="solutions-for-chapter-refchreg.html"><a href="solutions-for-chapter-refchreg.html"><i class="fa fa-check"></i><b>12.2</b> Solutions for chapter @ref(ch:reg) </a></li>
<li class="chapter" data-level="12.3" data-path="solutions-for-chapter-refchhierarchical.html"><a href="solutions-for-chapter-refchhierarchical.html"><i class="fa fa-check"></i><b>12.3</b> Solutions for chapter @ref(ch:hierarchical) </a></li>
<li class="chapter" data-level="12.4" data-path="solutions-for-chapter-refchbf.html"><a href="solutions-for-chapter-refchbf.html"><i class="fa fa-check"></i><b>12.4</b> Solutions for chapter @ref(ch:bf) </a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Bayesian Data Analysis for Cognitive Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="solutions-for-chapter-refchreg" class="section level2">
<h2><span class="header-section-number">12.2</span> Solutions for chapter <a href="ch-reg.html#ch:reg">4</a> </h2>
<ul>
<li>Exercise <a href="exercises-2.html#ex:reg-priors">4.6.1.1</a></li>
</ul>
<p>We can use a similar approach to the one used in <code>normal_predictive_distribution_fast</code> with <code>pmap_dfr</code> that iterates over the elements of each prior distribution and simulates values for each <code>c_load</code>.<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a></p>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb291-1" data-line-number="1">N_samples &lt;-<span class="st"> </span><span class="dv">1000</span></a>
<a class="sourceLine" id="cb291-2" data-line-number="2">N_obs &lt;-<span class="st"> </span><span class="kw">nrow</span>(df_pupil_data)</a>
<a class="sourceLine" id="cb291-3" data-line-number="3">alpha &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N_samples, <span class="dv">1000</span>, <span class="dv">500</span>)</a>
<a class="sourceLine" id="cb291-4" data-line-number="4">beta &lt;-<span class="st">  </span><span class="kw">rnorm</span>(N_samples, <span class="dv">0</span>, <span class="dv">100</span>)</a>
<a class="sourceLine" id="cb291-5" data-line-number="5">sigma &lt;-<span class="st"> </span><span class="kw">rtnorm</span>(N_samples, <span class="dv">100</span>, <span class="dv">10</span>, <span class="dt">a =</span> <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb291-6" data-line-number="6"></a>
<a class="sourceLine" id="cb291-7" data-line-number="7">prior_pred_pupil &lt;-<span class="st"> </span><span class="kw">pmap_dfr</span>(<span class="kw">list</span>(alpha, beta, sigma),</a>
<a class="sourceLine" id="cb291-8" data-line-number="8">                             <span class="cf">function</span>(a, b, s){</a>
<a class="sourceLine" id="cb291-9" data-line-number="9">                               <span class="kw">tibble</span>(<span class="dt">p_size_pred =</span> <span class="kw">rnorm</span>(N_obs, a <span class="op">+</span><span class="st"> </span>df_pupil_data<span class="op">$</span>c_load <span class="op">*</span><span class="st"> </span>b, s),</a>
<a class="sourceLine" id="cb291-10" data-line-number="10">                                      <span class="dt">c_load =</span> df_pupil_data<span class="op">$</span>c_load)</a>
<a class="sourceLine" id="cb291-11" data-line-number="11">                             }, <span class="dt">.id =</span> <span class="st">&quot;iter&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb291-12" data-line-number="12"><span class="st">  </span><span class="co"># .id is always a string and needs to be converted to a number</span></a>
<a class="sourceLine" id="cb291-13" data-line-number="13"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">iter =</span> <span class="kw">as.numeric</span>(iter))</a></code></pre></div>
<p>We plot some instances of the prior predictive distributions to evaluate them:</p>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb292-1" data-line-number="1">prior_pred_pupil <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb292-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(iter <span class="op">&lt;=</span><span class="st"> </span><span class="dv">18</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb292-3" data-line-number="3"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(p_size_pred)) <span class="op">+</span></a>
<a class="sourceLine" id="cb292-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_histogram</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb292-5" data-line-number="5"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>iter, <span class="dt">ncol =</span> <span class="dv">3</span>)</a></code></pre></div>
<p><img src="bookdown_files/figure-html/priorpred-pupil-1.svg" width="672" /></p>
<p>They don’t look too good, we are assuming that pupil sizes can be even negative!</p>
<ul>
<li>Exercise <a href="exercises-2.html#ex:reg-priorpost">4.6.1.2</a></li>
</ul>
<p>Our choice of prior for <span class="math inline">\(\sigma\)</span> might have been too wide leading to too much variation in the prior predictive distribution. We’ll check if our estimates change when we select a more reasonable prior.</p>
<p><span class="math display">\[\begin{equation}
\sigma \sim Normal_+(100, 100)
\end{equation}\]</span></p>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb293-1" data-line-number="1">fit_pupil_sigma2 &lt;-<span class="st"> </span><span class="kw">brm</span>(p_size <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>c_load,</a>
<a class="sourceLine" id="cb293-2" data-line-number="2">                 <span class="dt">data =</span> df_pupil_data,</a>
<a class="sourceLine" id="cb293-3" data-line-number="3">                 <span class="dt">family =</span> <span class="kw">gaussian</span>(),</a>
<a class="sourceLine" id="cb293-4" data-line-number="4">                 <span class="dt">prior =</span> <span class="kw">c</span>(</a>
<a class="sourceLine" id="cb293-5" data-line-number="5">                     <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">1000</span>, <span class="dv">500</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb293-6" data-line-number="6">                     <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">100</span>, <span class="dv">100</span>), <span class="dt">class =</span> sigma),</a>
<a class="sourceLine" id="cb293-7" data-line-number="7">                     <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="dt">class =</span> b, <span class="dt">coef =</span> c_load)</a>
<a class="sourceLine" id="cb293-8" data-line-number="8">                 )) </a></code></pre></div>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb294-1" data-line-number="1">fit_pupil_sigma2</a></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: p_size ~ 1 + c_load 
##    Data: df_pupil_data (Number of observations: 41) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat
## Intercept   700.98     20.14   661.89   740.45 1.00
## c_load       34.18     12.06    10.37    57.36 1.00
##           Bulk_ESS Tail_ESS
## Intercept     3648     2833
## c_load        3750     2802
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat
## sigma   127.62     14.58   103.11   159.26 1.00
##       Bulk_ESS Tail_ESS
## sigma     3159     2976
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>We see that our estimates remain virtually identical.</p>
<ul>
<li>Exercise <a href="exercises-2.html#ex:reg-pupiltrial">4.6.1.3</a></li>
</ul>
<p>As we did with pupil size, we first create a centered version of trial:</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb296-1" data-line-number="1">df_pupil_data &lt;-<span class="st"> </span>df_pupil_data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">c_trial =</span> trial <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(trial)) </a></code></pre></div>
<p>We’ll fit a model with the following likelihood:</p>
<p><span class="math display">\[\begin{equation}
p\_size_n \sim Normal(\alpha + c\_load_n \cdot \beta_1 + c\_trial_n \cdot \beta_2, \sigma )
\end{equation}\]</span></p>
<p>The formula will look like this <code>1 + c_load + c_trial</code>. We can see the new priors that the model needs by doing the following:</p>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb297-1" data-line-number="1"><span class="kw">get_prior</span>(p_size <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>c_load <span class="op">+</span><span class="st"> </span>c_trial,</a>
<a class="sourceLine" id="cb297-2" data-line-number="2">          <span class="dt">data =</span> df_pupil_data,</a>
<a class="sourceLine" id="cb297-3" data-line-number="3">          <span class="dt">family =</span> <span class="kw">gaussian</span>())</a></code></pre></div>
<pre><code>##                    prior     class    coef group resp
## 1 student_t(3, 687, 125) Intercept                   
## 2                                b                   
## 3                                b  c_load           
## 4                                b c_trial           
## 5   student_t(3, 0, 125)     sigma                   
##   dpar nlpar bound
## 1                 
## 2                 
## 3                 
## 4                 
## 5</code></pre>
<p>For simplicity, we assign the same prior distribution to both <span class="math inline">\(\beta\)</span> parameters.</p>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb299-1" data-line-number="1">fit_pupil_trial &lt;-<span class="st"> </span><span class="kw">brm</span>(p_size <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>c_load <span class="op">+</span><span class="st"> </span>c_trial,</a>
<a class="sourceLine" id="cb299-2" data-line-number="2">                 <span class="dt">data =</span> df_pupil_data,</a>
<a class="sourceLine" id="cb299-3" data-line-number="3">                 <span class="dt">family =</span> <span class="kw">gaussian</span>(),</a>
<a class="sourceLine" id="cb299-4" data-line-number="4">                 <span class="dt">prior =</span> <span class="kw">c</span>(</a>
<a class="sourceLine" id="cb299-5" data-line-number="5">                     <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">1000</span>, <span class="dv">500</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb299-6" data-line-number="6">                     <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1000</span>), <span class="dt">class =</span> sigma),</a>
<a class="sourceLine" id="cb299-7" data-line-number="7">                     <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="dt">class =</span> b)</a>
<a class="sourceLine" id="cb299-8" data-line-number="8">                 )) </a></code></pre></div>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb300-1" data-line-number="1">fit_pupil_trial</a></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: p_size ~ 1 + c_load + c_trial 
##    Data: df_pupil_data (Number of observations: 41) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat
## Intercept   701.43     17.48   667.47   736.45 1.00
## c_load       32.32     10.05    12.18    51.68 1.00
## c_trial      -5.47      1.47    -8.38    -2.56 1.00
##           Bulk_ESS Tail_ESS
## Intercept     4717     2550
## c_load        4302     3095
## c_trial       4015     3195
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat
## sigma   110.00     12.85    88.40   138.93 1.00
##       Bulk_ESS Tail_ESS
## sigma     4194     3094
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>The summary of the posterior tells us that the most likely values of the effect of load will be around the mean of the posterior, 32.32, and we can be 95% certain that the true value of the effect of load (given the model and the data) lies between 12.18 and 51.68. As before, as load increases the pupil size increases. The mean of the posterior for the effect of trial will be -5.47, with a 95% credible interval of <span class="math inline">\([-8.38, -2.56]\)</span>; this is telling us that as the trials proceed further, the pupil size is reduced.</p>
<ul>
<li>Exercise <a href="exercises-2.html#ex:reg-lognslowdown">4.6.2.1</a></li>
</ul>
<p>We look at what happens between the last two trials in milliseconds in the following way:</p>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb302-1" data-line-number="1">alpha_samples &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(fit_press_trial)<span class="op">$</span>b_Intercept</a>
<a class="sourceLine" id="cb302-2" data-line-number="2">beta_samples &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(fit_press_trial)<span class="op">$</span>b_c_trial</a>
<a class="sourceLine" id="cb302-3" data-line-number="3">last_trial &lt;-<span class="st"> </span>df_noreading_data<span class="op">$</span>c_trial <span class="op">%&gt;%</span><span class="st"> </span>max</a>
<a class="sourceLine" id="cb302-4" data-line-number="4">effect_end_ms &lt;-<span class="st"> </span><span class="kw">exp</span>(alpha_samples <span class="op">+</span><span class="st"> </span>last_trial <span class="op">*</span><span class="st"> </span>beta_samples) <span class="op">-</span></a>
<a class="sourceLine" id="cb302-5" data-line-number="5"><span class="st">  </span><span class="kw">exp</span>(alpha_samples <span class="op">+</span><span class="st"> </span>(last_trial <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)<span class="op">*</span><span class="st"> </span>beta_samples)</a>
<a class="sourceLine" id="cb302-6" data-line-number="6"><span class="kw">c</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(effect_end_ms), <span class="kw">quantile</span>(effect_end_ms, <span class="kw">c</span>(.<span class="dv">025</span>,.<span class="dv">975</span>)))</a></code></pre></div>
<pre><code>##  mean  2.5%   98% 
## 0.097 0.072 0.122</code></pre>
<ul>
<li>Exercise <a href="exercises-2.html#ex:reg-transf-trials">4.6.2.2</a></li>
</ul>
<p>We first create the new predictors:</p>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb304-1" data-line-number="1">df_noreading_data &lt;-<span class="st"> </span>df_noreading_data <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb304-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">c_log_trial =</span> <span class="kw">log</span>(trialn) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(<span class="kw">log</span>(trialn)),</a>
<a class="sourceLine" id="cb304-3" data-line-number="3">         <span class="dt">c_sqrt_trial =</span> <span class="kw">sqrt</span>(trialn) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(<span class="kw">sqrt</span>(trialn)))</a></code></pre></div>
<p>We start with log trial. The slope (<span class="math inline">\(\beta\)</span>) now represents the change in log reaction times when we move from the centered log transformed trial (<code>c_log_trial</code>) 0 to 1, which corresponds to going from trial 1 to trial “2.72” (because <span class="math inline">\(\exp(0)= 1\)</span> and <span class="math inline">\(\exp(1) = 2.72\)</span>). However the scale is not linear, and thus when we move from log transformed trials 2 to 3, it represents going from trial “7.39” to trial “20.09” (because <span class="math inline">\(\exp(2)= 7.39\)</span> and <span class="math inline">\(\exp(3) = 20.09\)</span>). This means that our prior for <span class="math inline">\(\beta\)</span> from section <a href="sec-trial.html#sec:trial">4.2</a> might be too restrictive, one unit for the new <span class="math inline">\(\beta\)</span> can be much more than one trial. We change the prior for <span class="math inline">\(\beta\)</span> in the next model to <span class="math inline">\(Normal(0, 1)\)</span>:</p>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb305-1" data-line-number="1">fit_press_log_trial &lt;-<span class="st"> </span><span class="kw">brm</span>(rt <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>c_log_trial,</a>
<a class="sourceLine" id="cb305-2" data-line-number="2">  <span class="dt">data =</span> df_noreading_data,</a>
<a class="sourceLine" id="cb305-3" data-line-number="3">  <span class="dt">family =</span> <span class="kw">lognormal</span>(),</a>
<a class="sourceLine" id="cb305-4" data-line-number="4">  <span class="dt">prior =</span> <span class="kw">c</span>(</a>
<a class="sourceLine" id="cb305-5" data-line-number="5">    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">6</span>, <span class="fl">1.5</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb305-6" data-line-number="6">    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sigma),</a>
<a class="sourceLine" id="cb305-7" data-line-number="7">    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> b, <span class="dt">coef =</span> c_log_trial)</a>
<a class="sourceLine" id="cb305-8" data-line-number="8">  )</a>
<a class="sourceLine" id="cb305-9" data-line-number="9">)</a></code></pre></div>
<p>We will look at the effect in milliseconds for the middle of the experiment. Thus we need to know <code>c_log_trial</code> at the middle and one trial before in our experiment. (Notice that it won’t be 0 and -1 as before).</p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb306-1" data-line-number="1">middle_log &lt;-<span class="st"> </span>df_noreading_data <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb306-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(c_trial <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb306-3" data-line-number="3"><span class="st">  </span><span class="kw">pull</span>(c_log_trial)</a>
<a class="sourceLine" id="cb306-4" data-line-number="4"><span class="co">## The old school way would be  &lt;- df_noreading_data[c_trial == 0]$c_log_trial</span></a>
<a class="sourceLine" id="cb306-5" data-line-number="5">middle_m1_log &lt;-<span class="st"> </span>df_noreading_data <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb306-6" data-line-number="6"><span class="st">  </span><span class="kw">filter</span>(c_trial <span class="op">==</span><span class="st"> </span><span class="dv">-1</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb306-7" data-line-number="7"><span class="st">  </span><span class="kw">pull</span>(c_log_trial)</a></code></pre></div>
<div class="sourceCode" id="cb307"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb307-1" data-line-number="1">alpha_samples &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(fit_press_log_trial)<span class="op">$</span>b_Intercept</a>
<a class="sourceLine" id="cb307-2" data-line-number="2">beta_samples &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(fit_press_log_trial)<span class="op">$</span>b_c_log_trial</a>
<a class="sourceLine" id="cb307-3" data-line-number="3">effect_middle_ms &lt;-<span class="st"> </span><span class="kw">exp</span>(alpha_samples <span class="op">+</span><span class="st"> </span>middle_log <span class="op">*</span><span class="st"> </span>beta_samples) <span class="op">-</span></a>
<a class="sourceLine" id="cb307-4" data-line-number="4"><span class="st">  </span><span class="kw">exp</span>(alpha_samples <span class="op">+</span><span class="st"> </span>middle_m1_log <span class="op">*</span><span class="st"> </span>beta_samples)</a>
<a class="sourceLine" id="cb307-5" data-line-number="5"><span class="kw">c</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(effect_middle_ms), <span class="kw">quantile</span>(effect_middle_ms, <span class="kw">c</span>(.<span class="dv">025</span>,.<span class="dv">975</span>)))</a></code></pre></div>
<pre><code>##  mean  2.5%   98% 
## 0.059 0.047 0.071</code></pre>
<p>We can do the same for square-root-transformed trials</p>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb309-1" data-line-number="1">fit_press_sqrt_trial &lt;-<span class="st"> </span><span class="kw">brm</span>(rt <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>c_sqrt_trial,</a>
<a class="sourceLine" id="cb309-2" data-line-number="2">  <span class="dt">data =</span> df_noreading_data,</a>
<a class="sourceLine" id="cb309-3" data-line-number="3">  <span class="dt">family =</span> <span class="kw">lognormal</span>(),</a>
<a class="sourceLine" id="cb309-4" data-line-number="4">  <span class="dt">prior =</span> <span class="kw">c</span>(</a>
<a class="sourceLine" id="cb309-5" data-line-number="5">    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">6</span>, <span class="fl">1.5</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb309-6" data-line-number="6">    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sigma),</a>
<a class="sourceLine" id="cb309-7" data-line-number="7">    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> b, <span class="dt">coef =</span> c_sqrt_trial)</a>
<a class="sourceLine" id="cb309-8" data-line-number="8">  )</a>
<a class="sourceLine" id="cb309-9" data-line-number="9">)</a></code></pre></div>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb310-1" data-line-number="1">middle_sqrt &lt;-<span class="st"> </span>df_noreading_data <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb310-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(c_trial <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb310-3" data-line-number="3"><span class="st">  </span><span class="kw">pull</span>(c_sqrt_trial)</a>
<a class="sourceLine" id="cb310-4" data-line-number="4">middle_m1_sqrt &lt;-<span class="st"> </span>df_noreading_data <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb310-5" data-line-number="5"><span class="st">  </span><span class="kw">filter</span>(c_trial <span class="op">==</span><span class="st"> </span><span class="dv">-1</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb310-6" data-line-number="6"><span class="st">  </span><span class="kw">pull</span>(c_sqrt_trial)</a></code></pre></div>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb311-1" data-line-number="1">alpha_samples &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(fit_press_sqrt_trial)<span class="op">$</span>b_Intercept</a>
<a class="sourceLine" id="cb311-2" data-line-number="2">beta_samples &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(fit_press_sqrt_trial)<span class="op">$</span>b_c_sqrt_trial</a>
<a class="sourceLine" id="cb311-3" data-line-number="3">effect_middle_ms &lt;-<span class="st"> </span><span class="kw">exp</span>(alpha_samples <span class="op">+</span><span class="st"> </span>middle_sqrt <span class="op">*</span><span class="st"> </span>beta_samples) <span class="op">-</span></a>
<a class="sourceLine" id="cb311-4" data-line-number="4"><span class="st">  </span><span class="kw">exp</span>(alpha_samples <span class="op">+</span><span class="st"> </span>middle_m1_sqrt <span class="op">*</span><span class="st"> </span>beta_samples)</a>
<a class="sourceLine" id="cb311-5" data-line-number="5"><span class="kw">c</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(effect_middle_ms), <span class="kw">quantile</span>(effect_middle_ms, <span class="kw">c</span>(.<span class="dv">025</span>,.<span class="dv">975</span>)))</a></code></pre></div>
<pre><code>##  mean  2.5%   98% 
## 0.083 0.065 0.101</code></pre>
<p>Let’s also look at the descriptive adequacy of these three models:</p>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb313-1" data-line-number="1"><span class="co"># I use imap to iterate accross the fit of the three models,</span></a>
<a class="sourceLine" id="cb313-2" data-line-number="2"><span class="co"># and create long df with predictions of the three models</span></a>
<a class="sourceLine" id="cb313-3" data-line-number="3">df_noreading_data_pred &lt;-</a>
<a class="sourceLine" id="cb313-4" data-line-number="4"><span class="st">  </span><span class="kw">imap_dfr</span>(<span class="kw">list</span>(<span class="dt">raw =</span> fit_press_trial, <span class="dt">log =</span> fit_press_log_trial, <span class="dt">sqrt =</span> fit_press_sqrt_trial),</a>
<a class="sourceLine" id="cb313-5" data-line-number="5">       <span class="cf">function</span>(fit, model){</a>
<a class="sourceLine" id="cb313-6" data-line-number="6">  <span class="kw">posterior_predict</span>(fit, <span class="dt">nsamples =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb313-7" data-line-number="7"><span class="st">    </span><span class="kw">array_branch</span>(<span class="dt">margin =</span> <span class="dv">1</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb313-8" data-line-number="8"><span class="st">    </span><span class="kw">map_dfr</span>( <span class="cf">function</span>(yrep_iter) {</a>
<a class="sourceLine" id="cb313-9" data-line-number="9">      df_noreading_data <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb313-10" data-line-number="10"><span class="st">        </span><span class="kw">mutate</span>(<span class="dt">rt =</span> yrep_iter,</a>
<a class="sourceLine" id="cb313-11" data-line-number="11">               <span class="dt">model =</span> model)</a>
<a class="sourceLine" id="cb313-12" data-line-number="12">    }, <span class="dt">.id =</span> <span class="st">&quot;iter&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb313-13" data-line-number="13"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">iter =</span> <span class="kw">as.numeric</span>(iter))</a>
<a class="sourceLine" id="cb313-14" data-line-number="14">       })</a></code></pre></div>
<p>We see that for the range of trials that we have in our experiment, the three models make very similar predictions:</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb314-1" data-line-number="1">df_noreading_pred_summary &lt;-<span class="st"> </span>df_noreading_data_pred <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb314-2" data-line-number="2"><span class="co"># I create 12 intervals of trials</span></a>
<a class="sourceLine" id="cb314-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">inter =</span> <span class="kw">cut</span>(trialn ,<span class="dt">breaks =</span> <span class="dv">12</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb314-4" data-line-number="4"><span class="st">    </span><span class="kw">group_by</span>(model, iter, inter) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb314-5" data-line-number="5"><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">rt =</span> <span class="kw">mean</span>(rt))</a>
<a class="sourceLine" id="cb314-6" data-line-number="6"></a>
<a class="sourceLine" id="cb314-7" data-line-number="7"><span class="co"># observed means:</span></a>
<a class="sourceLine" id="cb314-8" data-line-number="8">df_noreading_summary&lt;-<span class="st"> </span>df_noreading_data <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb314-9" data-line-number="9"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">inter =</span> <span class="kw">cut</span>(trialn ,<span class="dt">breaks =</span> <span class="dv">12</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb314-10" data-line-number="10"><span class="st">    </span><span class="kw">group_by</span>(inter) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb314-11" data-line-number="11"><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">rt =</span> <span class="kw">mean</span>(rt))</a>
<a class="sourceLine" id="cb314-12" data-line-number="12"><span class="kw">ggplot</span>(df_noreading_pred_summary, <span class="kw">aes</span>(rt)) <span class="op">+</span></a>
<a class="sourceLine" id="cb314-13" data-line-number="13"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">alpha=</span>.<span class="dv">5</span>, <span class="kw">aes</span>(<span class="dt">fill =</span> model), <span class="dt">position =</span> <span class="st">&#39;identity&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb314-14" data-line-number="14"><span class="st">    </span><span class="kw">geom_vline</span>(<span class="kw">aes</span>(<span class="dt">xintercept=</span> rt), <span class="dt">data=</span> df_noreading_summary)<span class="op">+</span></a>
<a class="sourceLine" id="cb314-15" data-line-number="15"><span class="st">    </span><span class="kw">facet_wrap</span>(inter <span class="op">~</span><span class="st"> </span>.)</a></code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-192-1.svg" width="672" /></p>
<ul>
<li>Exercise <a href="exercises-2.html#ex:reg-logistic-position">4.6.3.1</a></li>
</ul>
<p>We don’t just center <code>tested</code>, because the number is relative to the number of items that could be recalled. For this reason we create a relative position column, that is position relative to the set size, so that 0 corresponds to the first position and 1 to the last one.</p>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb315-1" data-line-number="1">df_recall_data &lt;-<span class="st"> </span>df_recall_data <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb315-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">c_rel_pos =</span> tested<span class="op">/</span>set_size <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(tested<span class="op">/</span>set_size))</a></code></pre></div>
<p>We assign the same priors to all slopes of our model:</p>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb316-1" data-line-number="1">fit_recall_tested &lt;-<span class="st"> </span><span class="kw">brm</span>(correct <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>c_set_size <span class="op">+</span><span class="st"> </span>c_rel_pos,</a>
<a class="sourceLine" id="cb316-2" data-line-number="2">                  <span class="dt">data =</span> df_recall_data,</a>
<a class="sourceLine" id="cb316-3" data-line-number="3">                  <span class="dt">family =</span> <span class="kw">bernoulli</span>(<span class="dt">link =</span> logit),</a>
<a class="sourceLine" id="cb316-4" data-line-number="4">                  <span class="dt">prior =</span> <span class="kw">c</span>(</a>
<a class="sourceLine" id="cb316-5" data-line-number="5">                    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">1.5</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb316-6" data-line-number="6">                    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">.1</span>), <span class="dt">class =</span> b)</a>
<a class="sourceLine" id="cb316-7" data-line-number="7">                  ))</a></code></pre></div>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb317-1" data-line-number="1">fit_recall_tested</a></code></pre></div>
<pre><code>##  Family: bernoulli 
##   Links: mu = logit 
## Formula: correct ~ 1 + c_set_size + c_rel_pos 
##    Data: df_recall_data (Number of observations: 92) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##            Estimate Est.Error l-95% CI u-95% CI Rhat
## Intercept      1.91      0.30     1.35     2.54 1.00
## c_set_size    -0.18      0.08    -0.34    -0.03 1.00
## c_rel_pos      0.01      0.10    -0.19     0.20 1.00
##            Bulk_ESS Tail_ESS
## Intercept      2962     2912
## c_set_size     3595     2763
## c_rel_pos      4228     3135
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>We generate posterior predictive distributions…</p>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb319-1" data-line-number="1">df_recall_pred &lt;-<span class="st"> </span><span class="kw">posterior_predict</span>(fit_recall_tested,</a>
<a class="sourceLine" id="cb319-2" data-line-number="2">                                 <span class="dt">nsamples =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb319-3" data-line-number="3"><span class="st">    </span><span class="kw">array_branch</span>(<span class="dt">margin =</span> <span class="dv">1</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb319-4" data-line-number="4"><span class="st">    </span><span class="kw">map_dfr</span>( <span class="cf">function</span>(yrep_iter) {</a>
<a class="sourceLine" id="cb319-5" data-line-number="5">        df_recall_data <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb319-6" data-line-number="6"><span class="st">            </span><span class="kw">mutate</span>(<span class="dt">correct =</span> yrep_iter)</a>
<a class="sourceLine" id="cb319-7" data-line-number="7">    }, <span class="dt">.id =</span> <span class="st">&quot;iter&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb319-8" data-line-number="8"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">iter =</span> <span class="kw">as.numeric</span>(iter))</a></code></pre></div>
<p>and plots that show the proportion of correct answers in our posterior predictive distribution contingent on the position and the set size.</p>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb320-1" data-line-number="1">df_recall_pred_summary &lt;-<span class="st"> </span>df_recall_pred <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb320-2" data-line-number="2"><span class="st">  </span><span class="kw">group_by</span>(iter, set_size, tested) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb320-3" data-line-number="3"><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">accuracy =</span> <span class="kw">mean</span>(correct))</a>
<a class="sourceLine" id="cb320-4" data-line-number="4"><span class="co"># observed means:</span></a>
<a class="sourceLine" id="cb320-5" data-line-number="5">df_recall_summary&lt;-<span class="st"> </span>df_recall_data <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb320-6" data-line-number="6"><span class="st">  </span><span class="kw">group_by</span>(set_size, tested) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb320-7" data-line-number="7"><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">accuracy =</span> <span class="kw">mean</span>(correct))</a>
<a class="sourceLine" id="cb320-8" data-line-number="8"><span class="kw">ggplot</span>(df_recall_pred_summary, <span class="kw">aes</span>(accuracy)) <span class="op">+</span></a>
<a class="sourceLine" id="cb320-9" data-line-number="9"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">alpha =</span> <span class="fl">.7</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb320-10" data-line-number="10"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="kw">aes</span>(<span class="dt">xintercept=</span> accuracy), <span class="dt">size =</span> <span class="fl">.5</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="dt">data=</span> df_recall_summary)<span class="op">+</span></a>
<a class="sourceLine" id="cb320-11" data-line-number="11"><span class="st">  </span><span class="kw">facet_grid</span>(set_size <span class="op">~</span><span class="st"> </span>tested, <span class="dt">labeller =</span> label_both)<span class="op">+</span></a>
<a class="sourceLine" id="cb320-12" data-line-number="12"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">.5</span>, <span class="dv">1</span>))</a></code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-196-1.svg" width="672" /></p>
<p>It seems that the position doesn’t matters too much except for the largest set size, where the first positions have lower accuracy than the later ones. Our simple model without an interaction is unable to capture this, but we should look at more data (probably the other subjects) to know if there is consistency in this pattern.</p>
<div style="page-break-after: always;"></div>
</div>
<div class="footnotes">
<hr />
<ol start="16">
<li id="fn16"><p>When the generative process starts to get complicated it might be worth it to generate the prior predictive distributions with <code>brms</code> as we did in the Appendix <a href="appendix.html#app:pp">3.9.1</a>.<a href="solutions-for-chapter-refchreg.html#fnref16" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="solutions-for-chapter-refchcompbda.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="solutions-for-chapter-refchhierarchical.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown/edit/master/inst/examples/98-solutions.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown.pdf", "bookdown.epub", "bookdown.mobi"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
