<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>12.1 Solutions for chapter 3  | An Introduction to Bayesian Data Analysis for Cognitive Science</title>
  <meta name="description" content="An introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="12.1 Solutions for chapter 3  | An Introduction to Bayesian Data Analysis for Cognitive Science" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://vasishth.github.io/Bayes_CogSci/" />
  <meta property="og:image" content="https://vasishth.github.io/Bayes_CogSci/images/temporarycover.jpg" />
  <meta property="og:description" content="An introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="github-repo" content="https://github.com/vasishth/Bayes_CogSci" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="12.1 Solutions for chapter 3  | An Introduction to Bayesian Data Analysis for Cognitive Science" />
  
  <meta name="twitter:description" content="An introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="twitter:image" content="https://vasishth.github.io/Bayes_CogSci/images/temporarycover.jpg" />

<meta name="author" content="Bruno Nicenboim, Daniel Schad, and Shravan Vasishth" />


<meta name="date" content="2020-06-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="solutions.html"/>
<link rel="next" href="solutions-for-chapter-refchreg.html"/>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<script type="text/javascript">

 /* Uncomment this and comment the next one to show the solutions */

 /* $(document).ready(function() {
  *     $folds = $(".solution");
  *     $folds.wrapInner("<div class=\"solution-blck\">"); // wrap a div container around content
  *     $folds.prepend("<button class=\"solution-btn\">Show solution</button>");  // add a button
  *     $(".solution-blck").toggle();  // fold all blocks
  *     $(".solution-btn").on("click", function() {  // add onClick event
  *         $(this).text($(this).text() === "Hide solution" ? "Show solution" : "Hide solution");  // if the text equals "Hide solution", change it to "Show solution"or else to "Hide solution" 
  *         $(this).next(".solution-blck").toggle("linear");  // "swing" is the default easing function. This can be further customized in its speed or the overall animation itself.
  *     })
  * }); */

 $(document).ready(function() {
     $folds = $(".solution");
     $folds.wrapInner("<div class=\"solution-blck\">"); // wrap a div container around content
     $folds.prepend("<button class=\"solution-btn\"></button>");  // add a button
     $(".solution-blck").toggle();  // fold all blocks
     $(".solution-btn").on("click", function() {  // add onClick event
         /* $(this).text($(this).text() === "Hide solution" ? "Show solution" : "Hide solution");  // if the text equals "Hide solution", change it to "Show solution"or else to "Hide solution"  */
         /* $(this).next(".solution-blck").toggle("linear");  // "swing" is the default easing function. This can be further customized in its speed or the overall animation itself. */
     })
 });

</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Data Analysis for Cognitive Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i><b>0.1</b> Prerequisites</a></li>
<li class="chapter" data-level="0.2" data-path="developing-the-right-mindset-for-this-book.html"><a href="developing-the-right-mindset-for-this-book.html"><i class="fa fa-check"></i><b>0.2</b> Developing the right mindset for this book</a></li>
<li class="chapter" data-level="0.3" data-path="how-to-read-this-book.html"><a href="how-to-read-this-book.html"><i class="fa fa-check"></i><b>0.3</b> How to read this book</a></li>
<li class="chapter" data-level="0.4" data-path="online-materials.html"><a href="online-materials.html"><i class="fa fa-check"></i><b>0.4</b> Online materials</a></li>
<li class="chapter" data-level="0.5" data-path="software-needed.html"><a href="software-needed.html"><i class="fa fa-check"></i><b>0.5</b> Software needed</a></li>
<li class="chapter" data-level="0.6" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i><b>0.6</b> Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introprob.html"><a href="introprob.html"><i class="fa fa-check"></i><b>1.1</b> Probability</a></li>
<li class="chapter" data-level="1.2" data-path="conditional-probability.html"><a href="conditional-probability.html"><i class="fa fa-check"></i><b>1.2</b> Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path="sec-binomialcloze.html"><a href="sec-binomialcloze.html"><i class="fa fa-check"></i><b>1.3</b> Discrete random variables: An example using the Binomial distribution</a><ul>
<li class="chapter" data-level="1.3.1" data-path="sec-binomialcloze.html"><a href="sec-binomialcloze.html#the-mean-and-variance-of-the-binomial-distribution"><i class="fa fa-check"></i><b>1.3.1</b> The mean and variance of the Binomial distribution</a></li>
<li class="chapter" data-level="1.3.2" data-path="sec-binomialcloze.html"><a href="sec-binomialcloze.html#what-information-does-a-probability-distribution-provide"><i class="fa fa-check"></i><b>1.3.2</b> What information does a probability distribution provide?</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="continuous-random-variables-an-example-using-the-normal-distribution.html"><a href="continuous-random-variables-an-example-using-the-normal-distribution.html"><i class="fa fa-check"></i><b>1.4</b> Continuous random variables: An example using the Normal distribution</a><ul>
<li class="chapter" data-level="1.4.1" data-path="continuous-random-variables-an-example-using-the-normal-distribution.html"><a href="continuous-random-variables-an-example-using-the-normal-distribution.html#an-important-distinction-probability-vs.density-in-a-continuous-random-variable"><i class="fa fa-check"></i><b>1.4.1</b> An important distinction: probability vs. density in a continuous random variable</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="an-important-concept-the-marginal-likelihood-integrating-out-a-parameter.html"><a href="an-important-concept-the-marginal-likelihood-integrating-out-a-parameter.html"><i class="fa fa-check"></i><b>1.5</b> An important concept: The marginal likelihood (integrating out a parameter)</a></li>
<li class="chapter" data-level="1.6" data-path="summary-of-useful-r-functions-relating-to-distributions.html"><a href="summary-of-useful-r-functions-relating-to-distributions.html"><i class="fa fa-check"></i><b>1.6</b> Summary of useful R functions relating to distributions</a></li>
<li class="chapter" data-level="1.7" data-path="summary-of-concepts-introduced-in-this-chapter.html"><a href="summary-of-concepts-introduced-in-this-chapter.html"><i class="fa fa-check"></i><b>1.7</b> Summary of concepts introduced in this chapter</a></li>
<li class="chapter" data-level="1.8" data-path="further-reading.html"><a href="further-reading.html"><i class="fa fa-check"></i><b>1.8</b> Further reading</a></li>
<li class="chapter" data-level="1.9" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.9</b> Exercises</a><ul>
<li class="chapter" data-level="1.9.1" data-path="exercises.html"><a href="exercises.html#practice-using-the-pnorm-function"><i class="fa fa-check"></i><b>1.9.1</b> Practice using the <code>pnorm</code> function</a></li>
<li class="chapter" data-level="1.9.2" data-path="exercises.html"><a href="exercises.html#practice-using-the-qnorm-function"><i class="fa fa-check"></i><b>1.9.2</b> Practice using the <code>qnorm</code> function</a></li>
<li class="chapter" data-level="1.9.3" data-path="exercises.html"><a href="exercises.html#practice-using-qt"><i class="fa fa-check"></i><b>1.9.3</b> Practice using <code>qt</code></a></li>
<li class="chapter" data-level="1.9.4" data-path="exercises.html"><a href="exercises.html#maximum-likelihood-estimation-1"><i class="fa fa-check"></i><b>1.9.4</b> Maximum likelihood estimation 1</a></li>
<li class="chapter" data-level="1.9.5" data-path="exercises.html"><a href="exercises.html#maximum-likelihood-estimation-2"><i class="fa fa-check"></i><b>1.9.5</b> Maximum likelihood estimation 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introBDA.html"><a href="introBDA.html"><i class="fa fa-check"></i><b>2</b> Introduction to Bayesian data analysis</a><ul>
<li class="chapter" data-level="2.1" data-path="sec-analytical.html"><a href="sec-analytical.html"><i class="fa fa-check"></i><b>2.1</b> Deriving the posterior using Bayes’ rule: An analytical example</a><ul>
<li class="chapter" data-level="2.1.1" data-path="sec-analytical.html"><a href="sec-analytical.html#choosing-a-likelihood"><i class="fa fa-check"></i><b>2.1.1</b> Choosing a likelihood</a></li>
<li class="chapter" data-level="2.1.2" data-path="sec-analytical.html"><a href="sec-analytical.html#choosing-a-prior-for-theta"><i class="fa fa-check"></i><b>2.1.2</b> Choosing a prior for <span class="math inline">\(\theta\)</span></a></li>
<li class="chapter" data-level="2.1.3" data-path="sec-analytical.html"><a href="sec-analytical.html#using-bayes-rule-to-compute-the-posterior-pthetank"><i class="fa fa-check"></i><b>2.1.3</b> Using Bayes’ rule to compute the posterior <span class="math inline">\(p(\theta|n,k)\)</span></a></li>
<li class="chapter" data-level="2.1.4" data-path="sec-analytical.html"><a href="sec-analytical.html#summary-of-the-procedure"><i class="fa fa-check"></i><b>2.1.4</b> Summary of the procedure</a></li>
<li class="chapter" data-level="2.1.5" data-path="sec-analytical.html"><a href="sec-analytical.html#visualizing-the-prior-likelihood-and-the-posterior"><i class="fa fa-check"></i><b>2.1.5</b> Visualizing the prior, likelihood, and the posterior</a></li>
<li class="chapter" data-level="2.1.6" data-path="sec-analytical.html"><a href="sec-analytical.html#the-posterior-distribution-is-a-compromise-between-the-prior-and-the-likelihood"><i class="fa fa-check"></i><b>2.1.6</b> The posterior distribution is a compromise between the prior and the likelihood</a></li>
<li class="chapter" data-level="2.1.7" data-path="sec-analytical.html"><a href="sec-analytical.html#incremental-knowledge-gain-using-prior-knowledge"><i class="fa fa-check"></i><b>2.1.7</b> Incremental knowledge gain using prior knowledge</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="summary-of-concepts-introduced-in-this-chapter-1.html"><a href="summary-of-concepts-introduced-in-this-chapter-1.html"><i class="fa fa-check"></i><b>2.2</b> Summary of concepts introduced in this chapter</a></li>
<li class="chapter" data-level="2.3" data-path="further-reading-1.html"><a href="further-reading-1.html"><i class="fa fa-check"></i><b>2.3</b> Further reading</a></li>
<li class="chapter" data-level="2.4" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>2.4</b> Exercises</a><ul>
<li class="chapter" data-level="2.4.1" data-path="exercises-1.html"><a href="exercises-1.html#exercise-deriving-bayes-rule"><i class="fa fa-check"></i><b>2.4.1</b> Exercise: Deriving Bayes’ rule</a></li>
<li class="chapter" data-level="2.4.2" data-path="exercises-1.html"><a href="exercises-1.html#exercise-conjugate-forms-1"><i class="fa fa-check"></i><b>2.4.2</b> Exercise: Conjugate forms 1</a></li>
<li class="chapter" data-level="2.4.3" data-path="exercises-1.html"><a href="exercises-1.html#exercise-conjugate-forms-2"><i class="fa fa-check"></i><b>2.4.3</b> Exercise: Conjugate forms 2</a></li>
<li class="chapter" data-level="2.4.4" data-path="exercises-1.html"><a href="exercises-1.html#exercise-conjugate-forms-3"><i class="fa fa-check"></i><b>2.4.4</b> Exercise: Conjugate forms 3</a></li>
<li class="chapter" data-level="2.4.5" data-path="exercises-1.html"><a href="exercises-1.html#exercise-conjugate-forms-4"><i class="fa fa-check"></i><b>2.4.5</b> Exercise: Conjugate forms 4</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch-compbda.html"><a href="ch-compbda.html"><i class="fa fa-check"></i><b>3</b> Computational Bayesian data analysis</a><ul>
<li class="chapter" data-level="3.1" data-path="deriving-the-posterior-through-sampling.html"><a href="deriving-the-posterior-through-sampling.html"><i class="fa fa-check"></i><b>3.1</b> Deriving the posterior through sampling</a><ul>
<li class="chapter" data-level="3.1.1" data-path="deriving-the-posterior-through-sampling.html"><a href="deriving-the-posterior-through-sampling.html#bayesian-regression-models-using-stan-brms"><i class="fa fa-check"></i><b>3.1.1</b> Bayesian Regression Models using ‘Stan’: brms</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sec-priorpred.html"><a href="sec-priorpred.html"><i class="fa fa-check"></i><b>3.2</b> Prior predictive distribution</a></li>
<li class="chapter" data-level="3.3" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html"><i class="fa fa-check"></i><b>3.3</b> The influence of priors: sensitivity analysis</a><ul>
<li class="chapter" data-level="3.3.1" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html#flat-uninformative-priors"><i class="fa fa-check"></i><b>3.3.1</b> Flat uninformative priors</a></li>
<li class="chapter" data-level="3.3.2" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html#regularizing-priors"><i class="fa fa-check"></i><b>3.3.2</b> Regularizing priors</a></li>
<li class="chapter" data-level="3.3.3" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html#principled-priors"><i class="fa fa-check"></i><b>3.3.3</b> Principled priors</a></li>
<li class="chapter" data-level="3.3.4" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html#informative-priors"><i class="fa fa-check"></i><b>3.3.4</b> Informative priors</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="sec-revisit.html"><a href="sec-revisit.html"><i class="fa fa-check"></i><b>3.4</b> Revisiting the button-pressing example with different priors</a></li>
<li class="chapter" data-level="3.5" data-path="sec-ppd.html"><a href="sec-ppd.html"><i class="fa fa-check"></i><b>3.5</b> Posterior predictive distribution</a><ul>
<li class="chapter" data-level="3.5.1" data-path="sec-ppd.html"><a href="sec-ppd.html#comparing-different-likelihoods"><i class="fa fa-check"></i><b>3.5.1</b> Comparing different likelihoods</a></li>
<li class="chapter" data-level="3.5.2" data-path="sec-ppd.html"><a href="sec-ppd.html#sec:lnfirst"><i class="fa fa-check"></i><b>3.5.2</b> The log-normal likelihood</a></li>
<li class="chapter" data-level="3.5.3" data-path="sec-ppd.html"><a href="sec-ppd.html#sec:lognormal"><i class="fa fa-check"></i><b>3.5.3</b> Re-fitting a single participant pressing a button repeatedly with a log-normal likelihood</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>3.6</b> Summary</a></li>
<li class="chapter" data-level="3.7" data-path="further-reading-2.html"><a href="further-reading-2.html"><i class="fa fa-check"></i><b>3.7</b> Further reading</a></li>
<li class="chapter" data-level="3.8" data-path="ex-compbda.html"><a href="ex-compbda.html"><i class="fa fa-check"></i><b>3.8</b> Exercises</a><ul>
<li class="chapter" data-level="3.8.1" data-path="ex-compbda.html"><a href="ex-compbda.html#a-simple-linear-model-exercises-section-refsecsimplenormal"><i class="fa fa-check"></i><b>3.8.1</b> A simple linear model exercises (Section @ref(sec:simplenormal))</a></li>
<li class="chapter" data-level="3.8.2" data-path="ex-compbda.html"><a href="ex-compbda.html#revisiting-the-button-pressing-example-with-different-priors-exercises-section-refsecrevisit"><i class="fa fa-check"></i><b>3.8.2</b> Revisiting the button-pressing example with different priors exercises (Section @ref(sec:revisit))</a></li>
<li class="chapter" data-level="3.8.3" data-path="ex-compbda.html"><a href="ex-compbda.html#posterior-predictive-distribution-and-log-normal-model-exercises-section-refsecppd"><i class="fa fa-check"></i><b>3.8.3</b> Posterior predictive distribution and log-normal model exercises (Section @ref(sec:ppd))</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>3.9</b> Appendix</a><ul>
<li class="chapter" data-level="3.9.1" data-path="appendix.html"><a href="appendix.html#app:pp"><i class="fa fa-check"></i><b>3.9.1</b> Generating prior predictive distributions with <code>brms</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-reg.html"><a href="ch-reg.html"><i class="fa fa-check"></i><b>4</b> Bayesian regression models</a><ul>
<li class="chapter" data-level="4.1" data-path="sec-pupil.html"><a href="sec-pupil.html"><i class="fa fa-check"></i><b>4.1</b> A first linear regression: Does attentional load affect pupil size?</a><ul>
<li class="chapter" data-level="4.1.1" data-path="sec-pupil.html"><a href="sec-pupil.html#likelihood-and-priors"><i class="fa fa-check"></i><b>4.1.1</b> Likelihood and priors</a></li>
<li class="chapter" data-level="4.1.2" data-path="sec-pupil.html"><a href="sec-pupil.html#the-brms-model"><i class="fa fa-check"></i><b>4.1.2</b> The <code>brms</code> model</a></li>
<li class="chapter" data-level="4.1.3" data-path="sec-pupil.html"><a href="sec-pupil.html#how-to-communicate-the-results"><i class="fa fa-check"></i><b>4.1.3</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.1.4" data-path="sec-pupil.html"><a href="sec-pupil.html#sec:pupiladq"><i class="fa fa-check"></i><b>4.1.4</b> Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sec-trial.html"><a href="sec-trial.html"><i class="fa fa-check"></i><b>4.2</b> Log-normal model: Does trial affect reaction times?</a><ul>
<li class="chapter" data-level="4.2.1" data-path="sec-trial.html"><a href="sec-trial.html#likelihood-and-priors-for-the-log-normal-model"><i class="fa fa-check"></i><b>4.2.1</b> Likelihood and priors for the log-normal model</a></li>
<li class="chapter" data-level="4.2.2" data-path="sec-trial.html"><a href="sec-trial.html#the-brms-model-1"><i class="fa fa-check"></i><b>4.2.2</b> The <code>brms</code> model</a></li>
<li class="chapter" data-level="4.2.3" data-path="sec-trial.html"><a href="sec-trial.html#how-to-communicate-the-results-1"><i class="fa fa-check"></i><b>4.2.3</b> How to communicate the results?</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="sec-logistic.html"><a href="sec-logistic.html"><i class="fa fa-check"></i><b>4.3</b> Logistic regression: Does set size affect free recall?</a><ul>
<li class="chapter" data-level="4.3.1" data-path="sec-logistic.html"><a href="sec-logistic.html#the-likelihood-for-the-logistic-regression-model"><i class="fa fa-check"></i><b>4.3.1</b> The likelihood for the logistic regression model</a></li>
<li class="chapter" data-level="4.3.2" data-path="sec-logistic.html"><a href="sec-logistic.html#priors-for-the-logistic-regression"><i class="fa fa-check"></i><b>4.3.2</b> Priors for the logistic regression</a></li>
<li class="chapter" data-level="4.3.3" data-path="sec-logistic.html"><a href="sec-logistic.html#the-brms-model-2"><i class="fa fa-check"></i><b>4.3.3</b> The <code>brms</code> model</a></li>
<li class="chapter" data-level="4.3.4" data-path="sec-logistic.html"><a href="sec-logistic.html#how-to-communicate-the-results-2"><i class="fa fa-check"></i><b>4.3.4</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.3.5" data-path="sec-logistic.html"><a href="sec-logistic.html#descriptive-adequacy"><i class="fa fa-check"></i><b>4.3.5</b> Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>4.4</b> Summary</a></li>
<li class="chapter" data-level="4.5" data-path="further-reading-3.html"><a href="further-reading-3.html"><i class="fa fa-check"></i><b>4.5</b> Further reading</a></li>
<li class="chapter" data-level="4.6" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a><ul>
<li class="chapter" data-level="4.6.1" data-path="exercises-2.html"><a href="exercises-2.html#a-first-linear-regression-exercises-section-refsecpupil"><i class="fa fa-check"></i><b>4.6.1</b> A first linear regression exercises (Section @ref(sec:pupil))</a></li>
<li class="chapter" data-level="4.6.2" data-path="exercises-2.html"><a href="exercises-2.html#log-normal-model-exercises-section-refsectrial"><i class="fa fa-check"></i><b>4.6.2</b> Log-normal model exercises (Section @ref(sec:trial))</a></li>
<li class="chapter" data-level="4.6.3" data-path="exercises-2.html"><a href="exercises-2.html#logistic-regression-exercises-section-refseclogistic"><i class="fa fa-check"></i><b>4.6.3</b> Logistic regression exercises (section @ref(sec:logistic))</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="appendix-1.html"><a href="appendix-1.html"><i class="fa fa-check"></i><b>4.7</b> Appendix</a><ul>
<li class="chapter" data-level="4.7.1" data-path="appendix-1.html"><a href="appendix-1.html#sec:preprocessingpupil"><i class="fa fa-check"></i><b>4.7.1</b> Preparation of the pupil size data (section @ref(sec:pupil))</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html"><i class="fa fa-check"></i><b>5</b> Bayesian hierarchical models</a><ul>
<li class="chapter" data-level="5.1" data-path="a-hierarchical-normal-model-the-n400-effect.html"><a href="a-hierarchical-normal-model-the-n400-effect.html"><i class="fa fa-check"></i><b>5.1</b> A hierarchical normal model: The N400 effect</a><ul>
<li class="chapter" data-level="5.1.1" data-path="a-hierarchical-normal-model-the-n400-effect.html"><a href="a-hierarchical-normal-model-the-n400-effect.html#complete-pooling-model-m_cp"><i class="fa fa-check"></i><b>5.1.1</b> Complete-pooling model (<span class="math inline">\(M_{cp}\)</span>)</a></li>
<li class="chapter" data-level="5.1.2" data-path="a-hierarchical-normal-model-the-n400-effect.html"><a href="a-hierarchical-normal-model-the-n400-effect.html#no-pooling-model-m_np"><i class="fa fa-check"></i><b>5.1.2</b> No-pooling model (<span class="math inline">\(M_{np}\)</span>)</a></li>
<li class="chapter" data-level="5.1.3" data-path="a-hierarchical-normal-model-the-n400-effect.html"><a href="a-hierarchical-normal-model-the-n400-effect.html#sec:uncorrelated"><i class="fa fa-check"></i><b>5.1.3</b> Varying intercept and varying slopes model (<span class="math inline">\(M_{v}\)</span>)</a></li>
<li class="chapter" data-level="5.1.4" data-path="a-hierarchical-normal-model-the-n400-effect.html"><a href="a-hierarchical-normal-model-the-n400-effect.html#sec:mcvivs"><i class="fa fa-check"></i><b>5.1.4</b> Correlated varying intercept varying slopes model (<span class="math inline">\(M_{h}\)</span>)</a></li>
<li class="chapter" data-level="5.1.5" data-path="a-hierarchical-normal-model-the-n400-effect.html"><a href="a-hierarchical-normal-model-the-n400-effect.html#sec:sih"><i class="fa fa-check"></i><b>5.1.5</b> By-subjects and by-items correlated varying intercept varying slopes model (<span class="math inline">\(M_{sih}\)</span>)</a></li>
<li class="chapter" data-level="5.1.6" data-path="a-hierarchical-normal-model-the-n400-effect.html"><a href="a-hierarchical-normal-model-the-n400-effect.html#sec:distrmodel"><i class="fa fa-check"></i><b>5.1.6</b> Beyond the so-called maximal models–Distributional regression models</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="sec-stroop.html"><a href="sec-stroop.html"><i class="fa fa-check"></i><b>5.2</b> A hierarchical log-normal model: The Stroop effect</a><ul>
<li class="chapter" data-level="5.2.1" data-path="sec-stroop.html"><a href="sec-stroop.html#a-correlated-varying-intercept-varying-slopes-log-normal-model"><i class="fa fa-check"></i><b>5.2.1</b> A correlated varying intercept varying slopes log-normal model</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="summary-2.html"><a href="summary-2.html"><i class="fa fa-check"></i><b>5.3</b> Summary</a><ul>
<li class="chapter" data-level="5.3.1" data-path="summary-2.html"><a href="summary-2.html#why-should-we-take-the-trouble-of-fitting-a-bayesian-hierarchical-model"><i class="fa fa-check"></i><b>5.3.1</b> Why should we take the trouble of fitting a Bayesian hierarchical model?</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="further-reading-4.html"><a href="further-reading-4.html"><i class="fa fa-check"></i><b>5.4</b> Further reading</a></li>
<li class="chapter" data-level="5.5" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>5.5</b> Exercises</a><ul>
<li class="chapter" data-level="5.5.1" data-path="exercises-3.html"><a href="exercises-3.html#ex:hierarchical-logn"><i class="fa fa-check"></i><b>5.5.1</b> Hierarchical model with a lognormal likelihood.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch-contr.html"><a href="ch-contr.html"><i class="fa fa-check"></i><b>6</b> Contrast coding, interactions, etc</a></li>
<li class="chapter" data-level="7" data-path="ch-bf.html"><a href="ch-bf.html"><i class="fa fa-check"></i><b>7</b> Model comparison using Bayes factors</a><ul>
<li class="chapter" data-level="7.1" data-path="summary-3.html"><a href="summary-3.html"><i class="fa fa-check"></i><b>7.1</b> Summary</a></li>
<li class="chapter" data-level="7.2" data-path="further-reading-5.html"><a href="further-reading-5.html"><i class="fa fa-check"></i><b>7.2</b> Further reading</a></li>
<li class="chapter" data-level="7.3" data-path="exercises-4.html"><a href="exercises-4.html"><i class="fa fa-check"></i><b>7.3</b> Exercises</a><ul>
<li class="chapter" data-level="7.3.1" data-path="exercises-4.html"><a href="exercises-4.html#ex:bf-logn"><i class="fa fa-check"></i><b>7.3.1</b> Bayes factor for a hierarchical model with a lognormal likelihood.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ch-remame.html"><a href="ch-remame.html"><i class="fa fa-check"></i><b>8</b> Meta-analysis and measurement error models</a></li>
<li class="chapter" data-level="9" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>9</b> Introduction</a></li>
<li class="chapter" data-level="10" data-path="meta-analysis.html"><a href="meta-analysis.html"><i class="fa fa-check"></i><b>10</b> Meta-analysis</a><ul>
<li class="chapter" data-level="10.0.1" data-path="meta-analysis.html"><a href="meta-analysis.html#random-effects-meta-analysis-brms-implementation"><i class="fa fa-check"></i><b>10.0.1</b> Random-effects meta-analysis: brms implementation</a></li>
<li class="chapter" data-level="10.0.2" data-path="meta-analysis.html"><a href="meta-analysis.html#random-effects-meta-analysis-stan-implementation"><i class="fa fa-check"></i><b>10.0.2</b> Random-effects meta-analysis: Stan implementation</a></li>
<li class="chapter" data-level="10.1" data-path="summary-4.html"><a href="summary-4.html"><i class="fa fa-check"></i><b>10.1</b> Summary</a></li>
<li class="chapter" data-level="10.2" data-path="further-reading-6.html"><a href="further-reading-6.html"><i class="fa fa-check"></i><b>10.2</b> Further reading</a></li>
<li class="chapter" data-level="10.3" data-path="exercises-5.html"><a href="exercises-5.html"><i class="fa fa-check"></i><b>10.3</b> Exercises</a><ul>
<li class="chapter" data-level="10.3.1" data-path="exercises-4.html"><a href="exercises-4.html#ex:bf-logn"><i class="fa fa-check"></i><b>10.3.1</b> Bayes factor for a hierarchical model with a lognormal likelihood.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="important-distributions.html"><a href="important-distributions.html"><i class="fa fa-check"></i><b>11</b> Important distributions</a></li>
<li class="chapter" data-level="12" data-path="solutions.html"><a href="solutions.html"><i class="fa fa-check"></i><b>12</b> Solutions</a><ul>
<li class="chapter" data-level="12.1" data-path="solutions-for-chapter-refchcompbda.html"><a href="solutions-for-chapter-refchcompbda.html"><i class="fa fa-check"></i><b>12.1</b> Solutions for chapter @ref(ch:compbda) </a></li>
<li class="chapter" data-level="12.2" data-path="solutions-for-chapter-refchreg.html"><a href="solutions-for-chapter-refchreg.html"><i class="fa fa-check"></i><b>12.2</b> Solutions for chapter @ref(ch:reg) </a></li>
<li class="chapter" data-level="12.3" data-path="solutions-for-chapter-refchhierarchical.html"><a href="solutions-for-chapter-refchhierarchical.html"><i class="fa fa-check"></i><b>12.3</b> Solutions for chapter @ref(ch:hierarchical) </a></li>
<li class="chapter" data-level="12.4" data-path="solutions-for-chapter-refchbf.html"><a href="solutions-for-chapter-refchbf.html"><i class="fa fa-check"></i><b>12.4</b> Solutions for chapter @ref(ch:bf) </a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Bayesian Data Analysis for Cognitive Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="solutions-for-chapter-refchcompbda" class="section level2">
<h2><span class="header-section-number">12.1</span> Solutions for chapter <a href="ch-compbda.html#ch:compbda">3</a> </h2>
<ul>
<li>Exercise <a href="ex-compbda.html#ex:compbda-fewiter">3.8.1.1</a></li>
</ul>
<p>We change the model so that <code>iter = 10</code> and <code>warmup = 5</code>. :</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb246-1" data-line-number="1">fit_press_bad &lt;-<span class="st"> </span><span class="kw">brm</span>(rt <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb246-2" data-line-number="2">  <span class="dt">data =</span> df_noreading_data,</a>
<a class="sourceLine" id="cb246-3" data-line-number="3">  <span class="dt">family =</span> <span class="kw">gaussian</span>(),</a>
<a class="sourceLine" id="cb246-4" data-line-number="4">  <span class="dt">prior =</span> <span class="kw">c</span>(</a>
<a class="sourceLine" id="cb246-5" data-line-number="5">    <span class="kw">prior</span>(<span class="kw">uniform</span>(<span class="dv">0</span>, <span class="dv">60000</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb246-6" data-line-number="6">    <span class="kw">prior</span>(<span class="kw">uniform</span>(<span class="dv">0</span>, <span class="dv">2000</span>), <span class="dt">class =</span> sigma)</a>
<a class="sourceLine" id="cb246-7" data-line-number="7">  ),</a>
<a class="sourceLine" id="cb246-8" data-line-number="8">  <span class="dt">chains =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb246-9" data-line-number="9">  <span class="dt">iter =</span> <span class="dv">10</span>,</a>
<a class="sourceLine" id="cb246-10" data-line-number="10">  <span class="dt">warmup =</span> <span class="dv">5</span></a>
<a class="sourceLine" id="cb246-11" data-line-number="11">)</a></code></pre></div>
<pre><code>## Warning: There were 20 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help. See
## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</code></pre>
<pre><code>## Warning: Examine the pairs() plot to diagnose sampling problems</code></pre>
<pre><code>## Warning: The largest R-hat is Inf, indicating chains have not mixed.
## Running the chains for more iterations may help. See
## http://mc-stan.org/misc/warnings.html#r-hat</code></pre>
<pre><code>## Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
## Running the chains for more iterations may help. See
## http://mc-stan.org/misc/warnings.html#bulk-ess</code></pre>
<pre><code>## Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
## Running the chains for more iterations may help. See
## http://mc-stan.org/misc/warnings.html#tail-ess</code></pre>
<p>This is definitely a bad idea. As it is clear from all the warnings, the number of iterations is not enough to achieve convergence. Let’s also take a look at the traceplots:</p>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb252-1" data-line-number="1"><span class="kw">plot</span>(fit_press_bad)</a></code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-157-1.svg" width="672" /></p>
<p>We see that the chains did not mix in the few iterations that were run. Notice that the warning messages convey important information, they suggest the following: <code>Running the chains for more iterations may help</code>.</p>
<ul>
<li>Exercise <a href="ex-compbda.html#ex:compbda-unif">3.8.1.2</a></li>
</ul>
<p>It’s more realistic to think that it’s impossible to press the spacebar in less than 50ms and for sure it won’t take more than 1 second; we change <span class="math inline">\(\mu\)</span> to reflect this. Furthermore, we don’t expect a standard deviation that exceeds 500 ms in reaction times since the participant is just pressing constantly the space bar; the standard deviation shouldn’t be shorter than 5 milliseconds no matter how steady the presses are; we change <span class="math inline">\(\sigma\)</span> to reflect this. We fit a new model as follows:</p>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb253-1" data-line-number="1">fit_press_personal &lt;-<span class="st"> </span><span class="kw">brm</span>(rt <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb253-2" data-line-number="2">  <span class="dt">data =</span> df_noreading_data,</a>
<a class="sourceLine" id="cb253-3" data-line-number="3">  <span class="dt">family =</span> <span class="kw">gaussian</span>(),</a>
<a class="sourceLine" id="cb253-4" data-line-number="4">  <span class="dt">prior =</span> <span class="kw">c</span>(</a>
<a class="sourceLine" id="cb253-5" data-line-number="5">    <span class="kw">prior</span>(<span class="kw">uniform</span>(<span class="dv">50</span>, <span class="dv">1000</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb253-6" data-line-number="6">    <span class="kw">prior</span>(<span class="kw">uniform</span>(<span class="dv">0</span>, <span class="dv">1000</span>), <span class="dt">class =</span> sigma)</a>
<a class="sourceLine" id="cb253-7" data-line-number="7">  ))</a></code></pre></div>
<pre><code>## Warning in .local(object, ...): some chains had errors;
## consider specifying chains = 1 to debug</code></pre>
<pre><code>## [[1]]
## Stan model &#39;54148c7f93924f5b50d22b60ea8de5c8&#39; does not contain samples.
## 
## [[2]]
## Stan model &#39;54148c7f93924f5b50d22b60ea8de5c8&#39; does not contain samples.
## 
## [[3]]
## Stan model &#39;54148c7f93924f5b50d22b60ea8de5c8&#39; does not contain samples.
## 
## [[4]]
## Stan model &#39;54148c7f93924f5b50d22b60ea8de5c8&#39; does not contain samples.</code></pre>
<p>What’s happening? The model cannot even start because the priors are too restrictive. In general, hard constraints on priors can be problematic unless the bounds represent true constraints (such as scale parameters being restricted to be positive, or correlations restricted to being between -1 and 1). While our original model worked (and you may come up with priors that work), once we constrain too much the interval of possible “true” values, we cannot even sample from the posterior. You can read more about computational and statistical issues with uniform interval priors in Bob Carpenter’s post (from Andrew Gelman’s blog):</p>
<p><a href="https://statmodeling.stat.columbia.edu/2017/11/28/computational-statistical-issues-uniform-interval-priors/" class="uri">https://statmodeling.stat.columbia.edu/2017/11/28/computational-statistical-issues-uniform-interval-priors/</a></p>
<ul>
<li>Exercise <a href="ex-compbda.html#ex:compbda-biasedpost">3.8.2.1</a></li>
</ul>
<p>This is actually not that easy, we need to include a lot of (false) certainty in the priors to achieve this. See the next model for example:</p>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb256-1" data-line-number="1">fit_press_too_inf &lt;-<span class="st"> </span><span class="kw">brm</span>(rt <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb256-2" data-line-number="2">  <span class="dt">data =</span> df_noreading_data,</a>
<a class="sourceLine" id="cb256-3" data-line-number="3">  <span class="dt">family =</span> <span class="kw">gaussian</span>(),</a>
<a class="sourceLine" id="cb256-4" data-line-number="4">  <span class="dt">prior =</span> <span class="kw">c</span>(</a>
<a class="sourceLine" id="cb256-5" data-line-number="5">    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">400</span>, <span class="dv">1</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb256-6" data-line-number="6">    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">100</span>, <span class="dv">10</span>), <span class="dt">class =</span> sigma)</a>
<a class="sourceLine" id="cb256-7" data-line-number="7">  )</a>
<a class="sourceLine" id="cb256-8" data-line-number="8">)</a></code></pre></div>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb257-1" data-line-number="1">fit_press_too_inf</a></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: rt ~ 1 
##    Data: df_noreading_data (Number of observations: 361) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat
## Intercept   397.72      0.98   395.80   399.65 1.00
##           Bulk_ESS Tail_ESS
## Intercept     3662     2749
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat
## sigma   190.08      4.77   180.96   199.62 1.00
##       Bulk_ESS Tail_ESS
## sigma     3139     2772
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Let’s see the new prior predictive distribution:</p>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb259-1" data-line-number="1">N_samples &lt;-<span class="st"> </span><span class="dv">1000</span></a>
<a class="sourceLine" id="cb259-2" data-line-number="2">N_obs &lt;-<span class="st"> </span><span class="kw">nrow</span>(df_noreading_data)</a>
<a class="sourceLine" id="cb259-3" data-line-number="3">mu_samples_too_inf &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N_samples, <span class="dv">400</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb259-4" data-line-number="4">sigma_samples_too_inf &lt;-<span class="st"> </span><span class="kw">rtnorm</span>(N_samples, <span class="dv">100</span>, <span class="dv">10</span>, <span class="dt">a =</span> <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb259-5" data-line-number="5"></a>
<a class="sourceLine" id="cb259-6" data-line-number="6">prior_pred_too_inf &lt;-<span class="st"> </span><span class="kw">normal_predictive_distribution_fast</span>(</a>
<a class="sourceLine" id="cb259-7" data-line-number="7">   <span class="dt">mu_samples =</span> mu_samples_too_inf,</a>
<a class="sourceLine" id="cb259-8" data-line-number="8">   <span class="dt">sigma_samples =</span> sigma_samples_too_inf,</a>
<a class="sourceLine" id="cb259-9" data-line-number="9">   N_obs)</a></code></pre></div>
<p>We plot the distributions to evaluate them:</p>

<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb260-1" data-line-number="1">prior_pred_too_inf <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb260-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(iter <span class="op">&lt;=</span><span class="st"> </span><span class="dv">18</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb260-3" data-line-number="3"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(rt_pred)) <span class="op">+</span></a>
<a class="sourceLine" id="cb260-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_histogram</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb260-5" data-line-number="5"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>iter, <span class="dt">ncol =</span> <span class="dv">3</span>)</a></code></pre></div>
<div class="figure"><span id="fig:priorpred-tooinf"></span>
<img src="bookdown_files/figure-html/priorpred-tooinf-1.svg" alt="Eighteen samples from the prior predictive distribution of the model with too informative priors." width="672" />
<p class="caption">
FIGURE 12.1: Eighteen samples from the prior predictive distribution of the model with too informative priors.
</p>
</div>
<p>We can also look at the distribution of statistics here.</p>

<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb261-1" data-line-number="1">prior_pred_too_inf <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb261-2" data-line-number="2"><span class="st">  </span><span class="kw">group_by</span>(iter) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb261-3" data-line-number="3"><span class="st">  </span><span class="kw">summarize</span>(</a>
<a class="sourceLine" id="cb261-4" data-line-number="4">    <span class="dt">min_rt =</span> <span class="kw">min</span>(rt_pred),</a>
<a class="sourceLine" id="cb261-5" data-line-number="5">    <span class="dt">max_rt =</span> <span class="kw">max</span>(rt_pred),</a>
<a class="sourceLine" id="cb261-6" data-line-number="6">    <span class="dt">average_rt =</span> <span class="kw">mean</span>(rt_pred)</a>
<a class="sourceLine" id="cb261-7" data-line-number="7">  ) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb261-8" data-line-number="8"><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="dt">cols =</span> <span class="kw">ends_with</span>(<span class="st">&quot;rt&quot;</span>),</a>
<a class="sourceLine" id="cb261-9" data-line-number="9">               <span class="dt">names_to =</span> <span class="st">&quot;stat&quot;</span>,</a>
<a class="sourceLine" id="cb261-10" data-line-number="10">               <span class="dt">values_to =</span> <span class="st">&quot;rt&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb261-11" data-line-number="11"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(rt)) <span class="op">+</span></a>
<a class="sourceLine" id="cb261-12" data-line-number="12"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">20</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb261-13" data-line-number="13"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>stat, <span class="dt">ncol =</span> <span class="dv">1</span>)</a></code></pre></div>
<div class="figure"><span id="fig:priorpred-stats-tooinf"></span>
<img src="bookdown_files/figure-html/priorpred-stats-tooinf-1.svg" alt="Prior predictive distribution of averages, maximum, and minimum value of the model defined in 3.1.1.1." width="672" />
<p class="caption">
FIGURE 12.2: Prior predictive distribution of averages, maximum, and minimum value of the model defined in <a href="deriving-the-posterior-through-sampling.html#sec:simplenormal">3.1.1.1</a>.
</p>
</div>
<p>The prior predictive distributions show that the priors are clearly too strong and informative restricting too much the possible values of <span class="math inline">\(/mu\)</span>.</p>
<ul>
<li>Exercise <a href="ex-compbda.html#ex:compbda-ppd">3.8.3.1</a></li>
</ul>
<p>We can use pretty much the same code as before, but we use samples from the posterior rather than from the priors.</p>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb262-1" data-line-number="1">N_obs &lt;-<span class="st"> </span><span class="kw">nrow</span>(df_noreading_data)</a>
<a class="sourceLine" id="cb262-2" data-line-number="2">mu_samples &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(fit_press_too_inf)<span class="op">$</span>b_Intercept</a>
<a class="sourceLine" id="cb262-3" data-line-number="3">sigma_samples &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(fit_press_too_inf)<span class="op">$</span>sigma</a>
<a class="sourceLine" id="cb262-4" data-line-number="4">posterior_pred_too_inf &lt;-<span class="st"> </span><span class="kw">normal_predictive_distribution_fast</span>(</a>
<a class="sourceLine" id="cb262-5" data-line-number="5">  <span class="dt">mu_samples =</span> mu_samples,</a>
<a class="sourceLine" id="cb262-6" data-line-number="6">  <span class="dt">sigma_samples =</span> sigma_samples,</a>
<a class="sourceLine" id="cb262-7" data-line-number="7">  N_obs</a>
<a class="sourceLine" id="cb262-8" data-line-number="8">)</a></code></pre></div>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb263-1" data-line-number="1">posterior_pred_too_inf <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb263-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(iter <span class="op">&lt;=</span><span class="st"> </span><span class="dv">18</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb263-3" data-line-number="3"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(rt_pred)) <span class="op">+</span></a>
<a class="sourceLine" id="cb263-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_histogram</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb263-5" data-line-number="5"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>iter, <span class="dt">ncol =</span> <span class="dv">3</span>)</a></code></pre></div>
<p><img src="bookdown_files/figure-html/posteriorpred-tooinf-1.svg" width="672" /></p>
<p>This shows that the posterior predictive distributions can also be affected by the priors (and not only the likelihood)! In general, a selection of priors that affects noticeably the posterior will also affect the posterior predictive distribution.</p>
<p>We can also use built-in functions to compare more easily the posterior predictive distributions with the observed distribution of reaction times:</p>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb264-1" data-line-number="1"><span class="kw">pp_check</span>(fit_press_too_inf, <span class="dt">nsamples =</span> <span class="dv">100</span>)</a></code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-163-1.svg" width="672" /></p>
<p>We see a very clear misfit.</p>
<ul>
<li>Exercise <a href="ex-compbda.html#ex:compbda-logn">3.8.3.2</a></li>
</ul>
<p>Recall that the parameters of the lognormal distribution are in a different scale than the output of the distribution. This new prior assumes a distribution of possible values of <span class="math inline">\(\sigma\)</span> as follows:</p>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb265-1" data-line-number="1"><span class="co"># Base plot can be useful for a quick and dirty plot here:</span></a>
<a class="sourceLine" id="cb265-2" data-line-number="2"><span class="kw">plot</span>(<span class="cf">function</span>(x) <span class="kw">dlnorm</span>(x, <span class="dv">-2</span>, <span class="fl">.5</span>))</a></code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-164-1.svg" width="672" /></p>
<p>We calculate median, mean, and 95% quantiles of the prior distribution of <span class="math inline">\(\sigma\)</span> by simulation (it is also possible to do it analytically):</p>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb266-1" data-line-number="1"><span class="kw">quantile</span>(<span class="kw">rlnorm</span>(<span class="dv">100000</span>, <span class="dv">-2</span>, <span class="fl">.5</span>), <span class="kw">c</span>(.<span class="dv">025</span>,.<span class="dv">975</span>))</a></code></pre></div>
<pre><code>##  2.5%   98% 
## 0.051 0.361</code></pre>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb268-1" data-line-number="1"><span class="kw">median</span>(<span class="kw">rlnorm</span>(<span class="dv">100000</span>, <span class="dv">-2</span>, <span class="fl">.5</span>))</a></code></pre></div>
<pre><code>## [1] 0.14</code></pre>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb270-1" data-line-number="1"><span class="kw">mean</span>(<span class="kw">rlnorm</span>(<span class="dv">100000</span>, <span class="dv">-2</span>, <span class="fl">.5</span>))</a></code></pre></div>
<pre><code>## [1] 0.15</code></pre>
<p>It looks that this prior would actually work quite well.
This is also evident from the prior predictive distributions of some representative statistics, which include reasonable values:</p>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb272-1" data-line-number="1">N_samples &lt;-<span class="st"> </span><span class="dv">1000</span></a>
<a class="sourceLine" id="cb272-2" data-line-number="2">N_obs &lt;-<span class="st"> </span><span class="kw">nrow</span>(df_noreading_data)</a>
<a class="sourceLine" id="cb272-3" data-line-number="3">mu_samples &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N_samples, <span class="dv">6</span>, <span class="fl">1.5</span>)</a>
<a class="sourceLine" id="cb272-4" data-line-number="4">sigma_samples &lt;-<span class="st"> </span><span class="kw">rlnorm</span>(N_samples, <span class="dv">-2</span>, <span class="fl">.5</span>)</a>
<a class="sourceLine" id="cb272-5" data-line-number="5">prior_pred_ln_new &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="kw">normal_predictive_distribution_fast</span>(</a>
<a class="sourceLine" id="cb272-6" data-line-number="6">  <span class="dt">mu_samples =</span> mu_samples,</a>
<a class="sourceLine" id="cb272-7" data-line-number="7">  <span class="dt">sigma_samples =</span> sigma_samples,</a>
<a class="sourceLine" id="cb272-8" data-line-number="8">  N_obs</a>
<a class="sourceLine" id="cb272-9" data-line-number="9">))</a>
<a class="sourceLine" id="cb272-10" data-line-number="10">prior_pred_ln_new <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb272-11" data-line-number="11"><span class="st">  </span><span class="kw">group_by</span>(iter) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb272-12" data-line-number="12"><span class="st">  </span><span class="kw">summarize</span>(</a>
<a class="sourceLine" id="cb272-13" data-line-number="13">    <span class="dt">min_rt =</span> <span class="kw">min</span>(rt_pred),</a>
<a class="sourceLine" id="cb272-14" data-line-number="14">    <span class="dt">max_rt =</span> <span class="kw">max</span>(rt_pred),</a>
<a class="sourceLine" id="cb272-15" data-line-number="15">    <span class="dt">average_rt =</span> <span class="kw">mean</span>(rt_pred),</a>
<a class="sourceLine" id="cb272-16" data-line-number="16">    <span class="dt">median_rt =</span> <span class="kw">median</span>(rt_pred)</a>
<a class="sourceLine" id="cb272-17" data-line-number="17">  ) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb272-18" data-line-number="18"><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="dt">cols =</span> <span class="kw">ends_with</span>(<span class="st">&quot;rt&quot;</span>),</a>
<a class="sourceLine" id="cb272-19" data-line-number="19">               <span class="dt">names_to =</span> <span class="st">&quot;stat&quot;</span>, <span class="dt">values_to =</span> <span class="st">&quot;rt&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb272-20" data-line-number="20"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(rt)) <span class="op">+</span></a>
<a class="sourceLine" id="cb272-21" data-line-number="21"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">trans =</span> <span class="st">&quot;log&quot;</span>, <span class="dt">breaks =</span> <span class="kw">c</span>(<span class="fl">0.001</span>, <span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10000</span>, <span class="dv">100000</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb272-22" data-line-number="22"><span class="st">  </span><span class="kw">geom_histogram</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb272-23" data-line-number="23"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>stat, <span class="dt">ncol =</span> <span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb272-24" data-line-number="24"><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="fl">0.001</span>, <span class="dv">300000</span>))</a></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value
## with `binwidth`.</code></pre>
<p><img src="bookdown_files/figure-html/unnamed-chunk-166-1.svg" width="672" /></p>
<p>We fit the model now:</p>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb274-1" data-line-number="1">fit_press_ln_new &lt;-<span class="st"> </span><span class="kw">brm</span>(rt <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb274-2" data-line-number="2">                    <span class="dt">data =</span> df_noreading_data,</a>
<a class="sourceLine" id="cb274-3" data-line-number="3">                    <span class="dt">family =</span> <span class="kw">lognormal</span>(),</a>
<a class="sourceLine" id="cb274-4" data-line-number="4">                    <span class="dt">prior =</span> <span class="kw">c</span>(</a>
<a class="sourceLine" id="cb274-5" data-line-number="5">                      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">6</span>, <span class="fl">1.5</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb274-6" data-line-number="6">                      <span class="kw">prior</span>(<span class="kw">lognormal</span>(<span class="op">-</span><span class="dv">2</span>, <span class="fl">.5</span>), <span class="dt">class =</span> sigma)</a>
<a class="sourceLine" id="cb274-7" data-line-number="7">                    )</a>
<a class="sourceLine" id="cb274-8" data-line-number="8">)</a></code></pre></div>
<div class="sourceCode" id="cb275"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb275-1" data-line-number="1">fit_press_ln_new</a></code></pre></div>
<pre><code>##  Family: lognormal 
##   Links: mu = identity; sigma = identity 
## Formula: rt ~ 1 
##    Data: df_noreading_data (Number of observations: 361) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat
## Intercept     5.12      0.01     5.10     5.13 1.00
##           Bulk_ESS Tail_ESS
## Intercept     3197     2594
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat
## sigma     0.13      0.01     0.13     0.15 1.00
##       Bulk_ESS Tail_ESS
## sigma     3010     2469
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>We see that estimates remain virtually the same as before.</p>
<ul>
<li>Exercise <a href="ex-compbda.html#ex:compbda-logn-mean-sd">3.8.3.3</a></li>
</ul>
<p>If we want to know how long it takes to press the space bar on average (rather than the median) in milliseconds, we need to transform <span class="math inline">\(\mu\)</span> using the following formula: <span class="math inline">\(\exp(\mu +\sigma ^{2}/2)\)</span> (it doesn’t really matter if we use <code>fit_press_ln</code> or <code>fit_press_ln_new</code> given that the estimates were so close to each other):</p>
<div class="sourceCode" id="cb277"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb277-1" data-line-number="1">mu &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(fit_press_ln)<span class="op">$</span>b_Intercept</a>
<a class="sourceLine" id="cb277-2" data-line-number="2">sigma &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(fit_press_ln)<span class="op">$</span>sigma</a>
<a class="sourceLine" id="cb277-3" data-line-number="3">mean_estimate_ms &lt;-<span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>(sigma <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">/</span><span class="dv">2</span>)</a></code></pre></div>
<p>Now we have 4000 samples of the posterior mean RT, we summarize it as follows:</p>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb278-1" data-line-number="1"><span class="kw">c</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(mean_estimate_ms), <span class="kw">quantile</span>(mean_estimate_ms, <span class="dt">probs =</span> <span class="kw">c</span>(.<span class="dv">025</span>, <span class="fl">.975</span>)))</a></code></pre></div>
<pre><code>## mean 2.5%  98% 
##  169  166  171</code></pre>
<p>For estimating the standard deviation of the reaction times we use the following formula <span class="math inline">\(\exp(\mu +\sigma ^{2}/2)\times \sqrt(\exp(\sigma^2)- 1)\)</span>:</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb280-1" data-line-number="1">sd_estimate_ms &lt;-<span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>(sigma <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">/</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">exp</span>(sigma<span class="op">^</span><span class="dv">2</span>)<span class="op">-</span><span class="dv">1</span>) </a></code></pre></div>
<p>Again we summarize it:</p>
<div class="sourceCode" id="cb281"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb281-1" data-line-number="1"><span class="kw">c</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(sd_estimate_ms), <span class="kw">quantile</span>(sd_estimate_ms, <span class="dt">probs =</span> <span class="kw">c</span>(.<span class="dv">025</span>, <span class="fl">.975</span>)))</a></code></pre></div>
<pre><code>## mean 2.5%  98% 
##   23   21   25</code></pre>
<ul>
<li>Exercise <a href="ex-compbda.html#ex:compbda-skew">3.8.3.4</a></li>
</ul>
<p>A simple prior that assigns approximately 95% of the prior probability mass of to be between 0 and 10 is a normal distribution centered in 5, where the <span class="math inline">\(\sigma\)</span> is 2.5. (This is because 95% of the probability mass of the normal distribution is contained between two standard deviations left and right from the mean.)</p>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb283-1" data-line-number="1"><span class="kw">quantile</span>(<span class="kw">rnorm</span>(<span class="dv">10000</span>, <span class="dv">5</span>, <span class="fl">2.5</span>),<span class="kw">c</span>(.<span class="dv">025</span>, <span class="fl">.975</span>))</a></code></pre></div>
<pre><code>##  2.5%   98% 
## 0.096 9.853</code></pre>
<p>We use this prior for <span class="math inline">\(\alpha\)</span> in the following model:</p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb285-1" data-line-number="1">fit_press_skew &lt;-<span class="st"> </span><span class="kw">brm</span>(rt <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb285-2" data-line-number="2">                    <span class="dt">data =</span> df_noreading_data,</a>
<a class="sourceLine" id="cb285-3" data-line-number="3">                    <span class="dt">family =</span> <span class="kw">skew_normal</span>(),</a>
<a class="sourceLine" id="cb285-4" data-line-number="4">                    <span class="dt">prior =</span> <span class="kw">c</span>(</a>
<a class="sourceLine" id="cb285-5" data-line-number="5">                      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">400</span>, <span class="dv">10</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb285-6" data-line-number="6">                      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">100</span>, <span class="dv">10</span>), <span class="dt">class =</span> sigma),</a>
<a class="sourceLine" id="cb285-7" data-line-number="7">                      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">5</span>, <span class="fl">2.5</span>), <span class="dt">class =</span> alpha)</a>
<a class="sourceLine" id="cb285-8" data-line-number="8">                    ))</a></code></pre></div>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb286-1" data-line-number="1">fit_press_skew</a></code></pre></div>
<pre><code>##  Family: skew_normal 
##   Links: mu = identity; sigma = identity; alpha = identity 
## Formula: rt ~ 1 
##    Data: df_noreading_data (Number of observations: 361) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat
## Intercept   174.95      1.64   171.86   178.30 1.00
##           Bulk_ESS Tail_ESS
## Intercept     1964     2553
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat
## sigma    27.18      1.41    24.62    30.24 1.00
## alpha     3.13      0.48     2.29     4.18 1.00
##       Bulk_ESS Tail_ESS
## sigma     1688     2190
## alpha     1785     1929
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Posterior predictive distributions can show us the fit of this new model:</p>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb288-1" data-line-number="1"><span class="kw">pp_check</span>(fit_press_skew, <span class="dt">nsamples =</span> <span class="dv">100</span>)</a></code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-176-1.svg" width="672" /></p>
<p>It’s not better than the fit of the “regular” normal distribution. We examine the distribution of minimum and maximum values below and we compare them with models that assume a “regular” normal distribution and log-normal distribution as likelihood functions.</p>
<div class="sourceCode" id="cb289"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb289-1" data-line-number="1"><span class="kw">pp_check</span>(fit_press, <span class="dt">type =</span> <span class="st">&quot;stat&quot;</span>, <span class="dt">stat =</span> <span class="st">&quot;min&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Normal model&quot;</span>)</a>
<a class="sourceLine" id="cb289-2" data-line-number="2"><span class="kw">pp_check</span>(fit_press_ln, <span class="dt">type =</span> <span class="st">&quot;stat&quot;</span>, <span class="dt">stat =</span> <span class="st">&quot;min&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Log-normal model&quot;</span>)</a>
<a class="sourceLine" id="cb289-3" data-line-number="3"><span class="kw">pp_check</span>(fit_press_skew, <span class="dt">type =</span> <span class="st">&quot;stat&quot;</span>, <span class="dt">stat =</span> <span class="st">&quot;min&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Skew normal model&quot;</span>)</a></code></pre></div>
<div class="figure"><span id="fig:ppcheckmin2"></span>
<img src="bookdown_files/figure-html/ppcheckmin2-1.svg" alt="Distribution of minimum values in a posterior predictive check." width="30%" /><img src="bookdown_files/figure-html/ppcheckmin2-2.svg" alt="Distribution of minimum values in a posterior predictive check." width="30%" /><img src="bookdown_files/figure-html/ppcheckmin2-3.svg" alt="Distribution of minimum values in a posterior predictive check." width="30%" />
<p class="caption">
FIGURE 12.3: Distribution of minimum values in a posterior predictive check.
</p>
</div>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb290-1" data-line-number="1"><span class="kw">pp_check</span>(fit_press, <span class="dt">type =</span> <span class="st">&quot;stat&quot;</span>, <span class="dt">stat =</span> <span class="st">&quot;max&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Normal model&quot;</span>)</a>
<a class="sourceLine" id="cb290-2" data-line-number="2"><span class="kw">pp_check</span>(fit_press_ln, <span class="dt">type =</span> <span class="st">&quot;stat&quot;</span>, <span class="dt">stat =</span> <span class="st">&quot;max&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Log-normal model&quot;</span>)</a>
<a class="sourceLine" id="cb290-3" data-line-number="3"><span class="kw">pp_check</span>(fit_press_skew, <span class="dt">type =</span> <span class="st">&quot;stat&quot;</span>, <span class="dt">stat =</span> <span class="st">&quot;max&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Skew normal model&quot;</span>)</a></code></pre></div>
<div class="figure"><span id="fig:ppcheckmax2"></span>
<img src="bookdown_files/figure-html/ppcheckmax2-1.svg" alt="Distribution of maximum values in a posterior predictive check. " width="30%" /><img src="bookdown_files/figure-html/ppcheckmax2-2.svg" alt="Distribution of maximum values in a posterior predictive check. " width="30%" /><img src="bookdown_files/figure-html/ppcheckmax2-3.svg" alt="Distribution of maximum values in a posterior predictive check. " width="30%" />
<p class="caption">
FIGURE 12.4: Distribution of maximum values in a posterior predictive check.
</p>
</div>
<div style="page-break-after: always;"></div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="solutions.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="solutions-for-chapter-refchreg.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown/edit/master/inst/examples/98-solutions.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown.pdf", "bookdown.epub", "bookdown.mobi"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
